{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"LangChain Hypothetical Document Embeddings (HyDE) 全面解説\"\n",
    "date: 2023-05-15\n",
    "description-meta: \"本文はHyDEの概念とLangchainでのその使い方を紹介しました。また、普通のEmbedding手法、HyDE、そして本文で提案したHyDE改善案、この三者の性能を比較しました。結論としてはHyDEはそれほど有効ではないことです。少し改善すれば性能は良くなりますが、検索スピードは非常に遅いですし、コストも大幅増加するので、ほぼ実用ではない手法といえます。\"\n",
    "categories: [NLP, LLMs, LangChain]\n",
    "format:\n",
    "    html:\n",
    "        mermaid:\n",
    "            theme: neutral\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本文の概要\n",
    "[Hypothetical Document Embeddings (HyDE)](https://arxiv.org/abs/2204.07496)は去年提出した情報検索の精度を向上させるための手法です。\n",
    "\n",
    "本文はHyDEの概念とLangchainでのその使い方を紹介しました。また、普通のEmbedding手法、HyDE、そして本文で提案したHyDE改善案、この三者の性能を比較しました。以下はテスト結果です。\n",
    "\n",
    "| 手法              | 正解数(50件の中) | MRR   | スピード  |\n",
    "|-----------------|------------|-------|-------|\n",
    "| 普通のEmbedding    | 37         | 0.855 | 17秒   |\n",
    "| HyDE            | 37         | 0.813 | 4分15秒 |\n",
    "| HyDE with title | 40         | 0.897 | 5分2秒  |\n",
    "\n",
    "<span style=\"background-color: yellow\">結論としてはHyDEはそれほど有効ではないことです。</span>少し改善すれば性能は良くなりますが、検索スピードは非常に遅いですし、コストも大幅増加するので、ほぼ実用ではない手法といえます。\n",
    "\n",
    "## Hypothetical Document Embeddings (HyDE)の詳細\n",
    "\n",
    "一般的なDense Information Retrievalの手順は以下のステップで行われます。\n",
    "\n",
    "1. QueryとDocument両方ともEmbedding(ベクトル)に変換する\n",
    "2. QueryとDocumentのコサイン類似度を計算する\n",
    "3. コサイン類似度が一番高いDocumentを返す\n",
    "\n",
    "```{mermaid}\n",
    "flowchart LR\n",
    "    Input[query]-->Embedding[query embedding]\n",
    "    Embedding-->DocumentEmbedding1[document embedding 1]\n",
    "    Embedding-->DocumentEmbedding2[document embedding 2]\n",
    "    Embedding-->DocumentEmbedding3[document embedding 3]\n",
    "\n",
    "    subgraph CosineSimilarity[cosine similarity]\n",
    "    DocumentEmbedding1-->CosineSimilarity1[0.1]\n",
    "    DocumentEmbedding2-->CosineSimilarity2[0.8]\n",
    "    DocumentEmbedding3-->CosineSimilarity3[0.3]\n",
    "    end\n",
    "    CosineSimilarity2-->FinalResult1[final result]\n",
    "```\n",
    "HyDEだと、`query embedding`のところに工夫しました。直接QueryをEmbeddingに変換するのではなく、まずQueryに答えるドキュメントをLLMに生成させて、生成した仮想な答案をEmbeddingに変換します。\n",
    "```{mermaid}\n",
    "flowchart LR\n",
    "    Input[query]-->LLM\n",
    "    subgraph HyDE\n",
    "    LLM-->FakeAnser[fake answer]\n",
    "    end\n",
    "        FakeAnser-->QueryEmbedding[query embedding]\n",
    "    QueryEmbedding-->DocumentEmbedding1[document embedding 1]\n",
    "    QueryEmbedding-->DocumentEmbedding2[document embedding 2]\n",
    "    QueryEmbedding-->DocumentEmbedding3[document embedding 3]\n",
    "    \n",
    "    subgraph CosineSimilarity[cosine similarity]\n",
    "    DocumentEmbedding1-->CosineSimilarity1[0.1]\n",
    "    DocumentEmbedding2-->CosineSimilarity2[0.8]\n",
    "    DocumentEmbedding3-->CosineSimilarity3[0.3]\n",
    "    end\n",
    "    CosineSimilarity2-->FinalResult1[final result]\n",
    "    style HyDE  stroke:#333,stroke-width:4px\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際にLangChainで使いましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import LLMChain, HypotheticalDocumentEmbedder\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "# set the environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# prepare the prompt template for document generation\n",
    "prompt_template = \"\"\"質問を回答しなさい。\n",
    "質問：{question}\n",
    "回答：\"\"\"\n",
    "llm = ChatOpenAI()\n",
    "# multi_llm = ChatOpenAI(n=4)\n",
    "prompt = PromptTemplate(input_variables=[\"question\"], template=prompt_template)\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt, verbose=True)\n",
    "\n",
    "# initialize the hypothetical document embedder\n",
    "base_embeddings = OpenAIEmbeddings()\n",
    "embeddings = HypotheticalDocumentEmbedder(llm_chain=llm_chain, base_embeddings=base_embeddings)\n",
    "\n",
    "result = embeddings.embed_query(\"ゼルダの伝説の主人公は誰ですか？\")\n",
    "len(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangchainでHyDEを使うには、まずは`HypotheticalDocumentEmbedder`を初期化する必要があります。初期化する際に必要なのは、仮想な答案を生成する`llm_chain`と生成したテキストをEmbeddingに変換する`base_embeddings`です。\n",
    "\n",
    ":::{.callout-tip}\n",
    "`llm`を定義する時、一度生成するドキュメントの数を指定できます。例えば`n`を`4`に指定すると、一度4つのドキュメントを生成します。\n",
    ":::\n",
    "\n",
    "使用する際には、`embedding.embed_query`を使ってQueryをEmbeddingに変換します。これで最終的に1536次元のベクトルが得られます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `HypotheticalDocumentEmbedder`の内部処理\n",
    "次に`HypotheticalDocumentEmbedder`の内部は同様な処理になっているかを見ましょう。コアの関数は以下の2つです。\n",
    "\n",
    "```python\n",
    "    def combine_embeddings(self, embeddings: List[List[float]]) -> List[float]:\n",
    "        \"\"\"Combine embeddings into final embeddings.\"\"\"\n",
    "        return list(np.array(embeddings).mean(axis=0))\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"Generate a hypothetical document and embedded it.\"\"\"\n",
    "        # generate n hypothetical documents\n",
    "        var_name = self.llm_chain.input_keys[0]\n",
    "        result = self.llm_chain.generate([{var_name: text}])\n",
    "        # get all the hypothetical documents from result\n",
    "        documents = [generation.text for generation in result.generations[0]]\n",
    "        # embed the hypothetical documents\n",
    "        embeddings = self.embed_documents(documents)\n",
    "        # combine the embeddings by averaging\n",
    "        return self.combine_embeddings(embeddings)\n",
    "```\n",
    "\n",
    "毎回2つ仮想な答案を生成する場合のフロー図にすると以下のようになります。\n",
    "\n",
    "```{mermaid}\n",
    "%%| fig-cap: \"HypotheticalDocumentEmbedderの処理の流れ\"\n",
    "flowchart LR\n",
    "    Input([query])-->llm_chain\n",
    "    subgraph HypotheticalDocumentEmbedder\n",
    "    llm_chain-->ga1([generated answer 1])\n",
    "    llm_chain-->ga2([generated answer 2])\n",
    "    ga1-->OpenAIEmbeddings\n",
    "    ga2-->OpenAIEmbeddings\n",
    "    OpenAIEmbeddings -->embed1([embedding 1])\n",
    "    OpenAIEmbeddings -->embed2([embedding 2])\n",
    "    end\n",
    "    embed1-->combine([averaged embedding])\n",
    "    embed2-->combine\n",
    "    style llm_chain  stroke:#333,stroke-width:4px\n",
    "    style OpenAIEmbeddings stroke:#333,stroke-width:4px\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実際のパフォーマンステスト\n",
    "HyDEは普通のEmbedding手法と比べてどのぐらい優れているかを実際に確認しましょう。\n",
    "\n",
    "使うデータは多言語質問応答データセットである「Mr.TyDi」にある日本語データです。各Queryに対して、Positive DocumentとNegative Documentが与えられています。また、Queryの内容は基本的にWikiで検索できる一般的な知識です。なので、今回のHyDEには非常に適していると思います。\n",
    "\n",
    "データはHuggingFaceのdatasetsからダウンロードします。データセットは7千件ありますが、コストを考慮して今回は100件のデータのみを使用します。また、テストする使うQueryの数は50件のみにします。つまり、50件のQueryに対して、合計200件(Pos + Neg)のドキュメントのランキングを行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "# to load all train, dev and test sets\n",
    "dataset = load_dataset('castorini/mr-tydi', \"japanese\", split=\"train\")\n",
    "tydi_df = pd.DataFrame(dataset).sample(100, random_state=42)\n",
    "for col in [\"positive_passages\", \"negative_passages\"]:\n",
    "    tydi_df[col] = tydi_df[col].apply(lambda x: x[0][\"text\"])\n",
    "tydi_df_sample = tydi_df.iloc[:50,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>positive_passages</th>\n",
       "      <th>negative_passages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>1320</td>\n",
       "      <td>有価証券とはなんですか？</td>\n",
       "      <td>有価証券（ゆうかしょうけん）とは、伝統的には財産的価値のある私権を表章する証券で、その権利の...</td>\n",
       "      <td>有価証券届出書の提出日以降、当該有価証券届出書の効力が発生する以前において、有価証券届出書に...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>862</td>\n",
       "      <td>浅草寺はいつ建設された</td>\n",
       "      <td>推古天皇36年（628年）、宮戸川（現・隅田川）で漁をしていた檜前浜成・竹成（ひのくまのはま...</td>\n",
       "      <td>1907年（明治40年）、昆虫学者名和靖は日露戦争の勝利記念に昆虫館を建設したいと考え、東京...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     query_id         query  \\\n",
       "1041     1320  有価証券とはなんですか？   \n",
       "670       862   浅草寺はいつ建設された   \n",
       "\n",
       "                                      positive_passages  \\\n",
       "1041  有価証券（ゆうかしょうけん）とは、伝統的には財産的価値のある私権を表章する証券で、その権利の...   \n",
       "670   推古天皇36年（628年）、宮戸川（現・隅田川）で漁をしていた檜前浜成・竹成（ひのくまのはま...   \n",
       "\n",
       "                                      negative_passages  \n",
       "1041  有価証券届出書の提出日以降、当該有価証券届出書の効力が発生する以前において、有価証券届出書に...  \n",
       "670   1907年（明治40年）、昆虫学者名和靖は日露戦争の勝利記念に昆虫館を建設したいと考え、東京...  "
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tydi_df_sample.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認する内容としては以下の3つとします。\n",
    "\n",
    "1. MRR: [Mean Reciprocal Rank](https://en.wikipedia.org/wiki/Mean_reciprocal_rank)、平均逆順位です。総合的にパフォーマンスを確認することができます。\n",
    "2. 正解数：上位1位は正解の数です。直感的にわかりやすいです。\n",
    "3. 検索にかかる時間：HyDEはLLMでテキスト生成を行なうため、検索時間が大幅に増える予想です。\n",
    "\n",
    "まずは、普通のEmbedding手法を使って場合のパフォーマンスをテストしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def get_rank(query, docs):\n",
    "    for i, doc in enumerate(docs, start=1):\n",
    "        if query == doc.metadata[\"query\"]:\n",
    "            return i\n",
    "\n",
    "def test(test_query_list, vectorstore):\n",
    "    # fetch the documents\n",
    "    rank_list = []\n",
    "    for title in tqdm(test_query_list):\n",
    "        docs = vectorstore.similarity_search(title, k=200)\n",
    "        rank_list.append(get_rank(title, docs))\n",
    "\n",
    "    # summarize the results\n",
    "    return rank_list\n",
    "\n",
    "def get_mrr(rank_list):\n",
    "    return sum([1/rank for rank in rank_list])/len(rank_list)\n",
    "def get_correct_num(rank_list):\n",
    "    return len([rank for rank in rank_list if rank == 1])\n",
    "\n",
    "# prepare the vectorstore\n",
    "docs = tydi_df[\"positive_passages\"].tolist() + tydi_df[\"negative_passages\"].tolist()\n",
    "meta_datas = [{\"query\": q} for q in tydi_df[\"query\"].tolist()] + [{\"query\": \"\"} for q in tydi_df[\"query\"].tolist()]\n",
    "base_embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_texts(\n",
    "    texts=docs,\n",
    "    embedding=base_embeddings,\n",
    "    metadatas=meta_datas,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b703a5ba7d438a8c0cf142d81c6992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rank_list = test(tydi_df_sample[\"query\"].tolist(), vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr: 0.855\n",
      "correct num: 37\n"
     ]
    }
   ],
   "source": [
    "print(f\"mrr: {get_mrr(rank_list):.3f}\")\n",
    "print(f\"correct num: {get_correct_num(rank_list)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "普通のEmbedding手法だと、50件のQueryの中、37件のドキュメントを正しく返せました。MRRは0.855、また、処理時間は17秒でした。\n",
    "\n",
    "次にHyDEを使ってテストします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "prompt_template = \"\"\"質問に答えてください。\n",
    "質問：{question}\n",
    "答案：\"\"\"\n",
    "llm = ChatOpenAI(verbose=True)\n",
    "prompt = PromptTemplate(input_variables=[\"question\"], template=prompt_template)\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt, verbose=True)\n",
    "embeddings = HypotheticalDocumentEmbedder(llm_chain=llm_chain, base_embeddings=base_embeddings)\n",
    "vectorstore.embedding_function = embeddings.embed_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622d58a347414a179630883cb6a6777a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hyde_rank_list = test(tydi_df_sample[\"query\"].tolist(), vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr: 0.813\n",
      "correct num: 35\n"
     ]
    }
   ],
   "source": [
    "print(f\"mrr: {get_mrr(hyde_rank_list):.3f}\")\n",
    "print(f\"correct num: {get_correct_num(hyde_rank_list)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "意外ですが、HyDEを使うと逆に正解数が減りました。正解数は35件、MRRは0.813、処理時間は4分15秒でした。\n",
    "\n",
    "## HyDEの改善\n",
    "HyDEは生成した仮想な答案をEmbeddingにしていますが、逆に重要なQueryの情報を捨てています。なので、仮想な答案をEmbeddingする前にQueryの情報を仮想な答案に加えることができれば、もっとパフォーマンスを改善できると考えられます。\n",
    "\n",
    "その改善をしてみましょう。そのためには、まず`HypotheticalDocumentEmbedder`を継承したクラスを作り、`embed_query`を再定義する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyDEWithTitle(HypotheticalDocumentEmbedder):\n",
    "\n",
    "    def embed_query(self, text: str):\n",
    "        \"\"\"Generate a hypothetical document and embedded it.\"\"\"\n",
    "        var_name = self.llm_chain.input_keys[0]\n",
    "        result = self.llm_chain.generate([{var_name: text}])\n",
    "        documents = [generation.text for generation in result.generations[0]]\n",
    "        # add query to the beginning of the document\n",
    "        documents = [f\"{text}\\n{document}\" for document in documents]\n",
    "        embeddings = self.embed_documents(documents)\n",
    "        return self.combine_embeddings(embeddings)\n",
    "\n",
    "embeddings = HyDEWithTitle(llm_chain=llm_chain, base_embeddings=base_embeddings)\n",
    "vectorstore.embedding_function = embeddings.embed_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b1d066e40b4a55805e3acbc74b3bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0d85be599b6abc67a7a59f467a5101cd in your message.).\n"
     ]
    }
   ],
   "source": [
    "hyde_with_title_rank_list = test(tydi_df_sample[\"query\"].tolist(), vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr: 0.897\n",
      "correct num: 40\n"
     ]
    }
   ],
   "source": [
    "print(f\"mrr: {get_mrr(hyde_with_title_rank_list):.3f}\")\n",
    "print(f\"correct num: {get_correct_num(hyde_with_title_rank_list)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "検索するQueryを仮想な答案に追加することにより、正解数が多くなりましたし、全体のランクも上がりました。\n",
    "\n",
    "## まとめ\n",
    "\n",
    "HyDEは予想より精度の改善が得られなかったです。Queryを仮想な答案に追加することにより、精度は普通のEmbedding手法より上がりました。しかし、処理時間が大幅に増えてしまいました。また、今回は測っていないですが、1件あたりのコストも何倍になると思うので、実際に使う場合は、精度と処理時間、コストを総合的に考えて使う必要があります。\n",
    "\n",
    "| 手法              | 正解数(50件の中) | MRR   | スピード  |\n",
    "|-----------------|------------|-------|-------|\n",
    "| 普通のEmbedding    | 37         | 0.855 | 17秒   |\n",
    "| HyDE            | 37         | 0.813 | 4分15秒 |\n",
    "| HyDE with title | 40         | 0.897 | 5分2秒  |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notion-db",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
