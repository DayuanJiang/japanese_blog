{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Multi-Vector Retrieverの使い方とその効果\"\n",
    "date: 2023-12-10\n",
    "description-meta: \"\"\n",
    "categories: [NLP, LLM, LangChain]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 内容概要\n",
    "\n",
    "この記事では、`Multi-Vector Retriever`の使用方法を紹介し、複数の実験を通じてその効果を検証しました。実験から得られた主な知見は以下の3点です。\n",
    "\n",
    "1. テキストを単純に結合してドキュメントにサマリーを追加すると、精度がむしろ低下することがわかりました。\n",
    "2. `Multi-Vector Retriever`を使用してもTop1の精度は向上しませんでしたが、MRR（平均逆順位）を見ると全体の精度が改善されていることが分かります。\n",
    "3. センテンスレベルでの検索が常に良い結果をもたらすわけではないことが明らかになりました。\n",
    "\n",
    "## Multi-Vector Retrieverについて\n",
    "\n",
    "`Multi-Vector Retriever`はLangChainシステムの検索機能の一つで、複数の埋め込みベクトルを使用して検索を行うことが特徴です。ドキュメントのサマリーを作成し、ドキュメントとサマリーの両方に対してベクトルを生成し、それらを用いて検索を行うことができます。\n",
    "\n",
    "## 簡単な使用例\n",
    "\n",
    "以下に簡単な使用例を説明します。\n",
    "\n",
    "### 初期化\n",
    "\n",
    "例えば、現在3つのドキュメントがあり、それぞれにサマリーを生成したとします。これらをすべて検索に使用したい場合、初期化する際にはまず、IDを付けてそれぞれのドキュメントを`docstore`に追加します。さらに、ドキュメントとサマリーの両方に`Metadata`としてIDを付け、ベクトルストアを作成する必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![初期化の説明](multi-vector_retriever_init.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.schema import Document\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# create 3 documents and its summaries\n",
    "docs = [\n",
    "    Document(page_content=\"doc\" + str(i), metadata={\"doc_id\": \"doc\" + str(i)})\n",
    "    for i in range(1, 4)\n",
    "] \n",
    "\n",
    "summarys = [\n",
    "    Document(page_content=\"summary\" + str(i), metadata={\"doc_id\": \"doc\" + str(i)})\n",
    "    for i in range(1, 4)\n",
    "]\n",
    "\n",
    "# initialize docstore\n",
    "docstore = InMemoryStore()\n",
    "docstore.mset(list(zip([\"doc\" + str(i) for i in range(1, 4)], docs)))\n",
    "\n",
    "# put documents and summaries in the vector store\n",
    "multi_vector_vectorstore = FAISS.from_documents(docs + summarys, OpenAIEmbeddings())\n",
    "\n",
    "# initialize retriever\n",
    "sample_retriever = MultiVectorRetriever(\n",
    "    vectorstore=multi_vector_vectorstore,\n",
    "    docstore=docstore,\n",
    "    id_key=\"doc_id\",\n",
    "    search_kwargs={\"k\": 4},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用方法\n",
    "\n",
    "使用方法は通常の`Retriever`と同様で、`get_relevant_documents`関数を呼び出すだけです。この関数内で行われるプロセスは、まずクエリを使ってVectorstoreで検索を行います。検索にヒットしたアイテムからIDを抽出し、そのIDを使用してDocstoreからドキュメントを取得し、結果を返します。\n",
    "\n",
    "ここでの注意点は、検索で`k=4`を指定した場合、上位4位の結果の中に`ID2`が2回出現することがあります。そのため、最終的な結果は4つではなく、3つのドキュメントが出力されることになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Multi-Vector Retriever検索の仕組み](multi-vector_retriever_retrieve.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='doc1', metadata={'doc_id': 'doc1'}),\n",
       " Document(page_content='doc2', metadata={'doc_id': 'doc2'}),\n",
       " Document(page_content='doc3', metadata={'doc_id': 'doc3'})]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_retriever.get_relevant_documents(\"doc1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "なお、LangChainにあるもう一個`Parent Document Retriever`はほぼこれと同じ概念です。なんでわざわざ2つ作ったかが謎です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実験結果\n",
    "以下の実験を行いました。\n",
    "\n",
    "  - サマリーを生成し、それをベクトルとして追加する  \n",
    "  - ドキュメントを文単位に切り、文単位で検索を行う  \n",
    "\n",
    "### 実験の設定\n",
    "使うデータはいつもの東京都立大学のeラーニングシステムのQ&Aデータです。このデータは、東京都立大学で導入されたeラーニングシステムのユーザーから2015年4月から2018年7月までに報告された問題点としてのQ&Aデータを収集したものです。427の質問と79の回答が含まれています。質問にどの回答に紐づくかのラベルがあります。\n",
    "\n",
    "データの様子は下記の通りです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_df.shape: (427, 2)\n",
      "a_df.shape: (79, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>AID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>履修している授業で先生が資料をアップロードしているはずだが、コース上に資料が見当たらない。</td>\n",
       "      <td>A001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>資料をマイページに置いたが、学生からは見えなかった。</td>\n",
       "      <td>A001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>前期の科目の「資料」を学生から見られないようにするにはどうしたら良いか？</td>\n",
       "      <td>A001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Text   AID\n",
       "0  履修している授業で先生が資料をアップロードしているはずだが、コース上に資料が見当たらない。  A001\n",
       "1                     資料をマイページに置いたが、学生からは見えなかった。  A001\n",
       "2           前期の科目の「資料」を学生から見られないようにするにはどうしたら良いか？  A001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A001</td>\n",
       "      <td>資料が見つからない場合は、以下の点を確認してください。  \\n  \\n  \\n【受講生編】 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A002</td>\n",
       "      <td>資料のアップロードやお知らせ作成時の電子メールでの通知の有無は、各授業の担当教員が設定できま...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A003</td>\n",
       "      <td>kibacoにはファイルへパスワードを設定する機能はありません。資料は受講生全員に開示されま...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AID                                               Text\n",
       "0  A001  資料が見つからない場合は、以下の点を確認してください。  \\n  \\n  \\n【受講生編】 ...\n",
       "1  A002  資料のアップロードやお知らせ作成時の電子メールでの通知の有無は、各授業の担当教員が設定できま...\n",
       "2  A003  kibacoにはファイルへパスワードを設定する機能はありません。資料は受講生全員に開示されま..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"実験用コード\"\n",
    "import pandas as pd\n",
    "import html2text\n",
    "# https://zenodo.org/record/2783642\n",
    "q_df = pd.read_csv(\"https://zenodo.org/record/2783642/files/Questions.csv\")\n",
    "a_df = pd.read_csv(\"https://zenodo.org/record/2783642/files/Answers.csv\")\n",
    "print(\"q_df.shape:\", q_df.shape)\n",
    "print(\"a_df.shape:\", a_df.shape)\n",
    "q_df.columns = [c.strip() for c in q_df.columns]\n",
    "a_df.columns = [c.strip() for c in a_df.columns]\n",
    "a_df[\"Text\"] = a_df[\"Text\"].apply(lambda x: html2text.html2text(x))\n",
    "df = q_df.merge(a_df, on=\"AID\")\n",
    "df.columns = [\"query\", \"AID\", \"document\"]\n",
    "\n",
    "metadata = a_df[[\"AID\"]].to_dict(orient=\"records\")\n",
    "documents = a_df[\"Text\"].tolist()\n",
    "query_list = list(zip(q_df[\"Text\"], q_df[\"AID\"]))\n",
    "display(q_df.head(3))\n",
    "display(a_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "評価指標は以下の3つです。\n",
    "\n",
    "1. Mean Reciprocal Rank（MRR）: 正解ドキュメントの順位の平均の逆数で、ランク全体を評価する指標。\n",
    "2. Recall@1: 正解ドキュメントが1番目に並んでいるかどうかを評価する指標。\n",
    "3. Recall@5: 正解ドキュメントが上位5位以内に入っているかどうかを評価する指標。\n",
    "\n",
    "その結果のまとめは以下になります。\n",
    "\n",
    "| 実験名              |    mrr |   recall_at_1 |   recall_at_5 |\n",
    "|:----------------------|-------:|--------------:|--------------:|\n",
    "| ドキュメントのみ              | 0.6777 |        **0.5457** |        0.8454 |\n",
    "| サマリーのみ               | 0.6475 |        0.5035 |        0.8244 |\n",
    "| **テキスト結合**<br>ドキュメント+サマリー         | 0.6612 |        0.5199 |        0.8407 |\n",
    "| **Multi-Vector Retriever**<br>ドキュメント+サマリー          | **0.683**  |        **0.5457** |        **0.8501** |\n",
    "| **Multi-Vector Retriever**<br>センテンスレベル    | 0.66   |        0.5199 |        0.8454 |\n",
    "\n",
    "実験からわかることとしては以下の3点です。\n",
    "\n",
    "1. テキストを単純に結合してドキュメントにサマリーを追加すると、精度がむしろ低下することがわかりました。\n",
    "2. `Multi-Vector Retriever`を使用してもTop1の精度は向上しませんでしたが、MRR（平均逆順位）を見ると全体の精度が改善されていることが分かります。\n",
    "3. センテンスレベルでの検索が常に良い結果をもたらすわけではないことが明らかになりました。\n",
    "\n",
    "## 実験の詳細 + コード\n",
    "\n",
    "実験の詳細は以下です。興味がある方が次にご覧ください。ちなみに、実験の効率化するために、並列化を行いました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"実験用コード\"\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from src.parallel import parallelize_function\n",
    "from dataclasses import dataclass\n",
    "\n",
    "DOC_NUM = len(a_df)\n",
    "\n",
    "@dataclass\n",
    "class EvaluationResults:\n",
    "    result_df: pd.DataFrame\n",
    "    mrr: float\n",
    "    recall_at_1: float\n",
    "    recall_at_5: float\n",
    "\n",
    "\n",
    "def mrr(rank_array):\n",
    "    return (1 / rank_array).mean()\n",
    "\n",
    "\n",
    "\n",
    "def recall_at_k(rank_array, k):\n",
    "    return (rank_array <= k).mean()\n",
    "\n",
    "\n",
    "# Define a function to be executed in parallel\n",
    "def evaluate_single_query(query_aid_tuple, search_func, doc_num):\n",
    "    query, aid = query_aid_tuple\n",
    "    search_result = search_func(query)\n",
    "    aid_list = []\n",
    "    for doc in search_result:\n",
    "        aid_list.append(doc.metadata[\"doc_id\"])\n",
    "    if aid not in aid_list:\n",
    "        rank = doc_num + 1\n",
    "    else:\n",
    "        rank = aid_list.index(aid) + 1\n",
    "    return query, rank, aid_list\n",
    "\n",
    "\n",
    "# Parallelized evaluate function\n",
    "def parallel_evaluate(\n",
    "    query_list, search_func, max_workers=20, doc_num=DOC_NUM\n",
    "):\n",
    "    # Prepare arguments for parallel execution\n",
    "    args_list = [\n",
    "        (query_aid, search_func, doc_num) for query_aid in query_list\n",
    "    ]\n",
    "\n",
    "    # Execute the evaluate_single_query function in parallel\n",
    "    results = parallelize_function(\n",
    "        evaluate_single_query, args_list, max_workers=max_workers\n",
    "    )\n",
    "\n",
    "    # Process results and create a DataFrame\n",
    "    result_list = [result for result in results if not isinstance(result, Exception)]\n",
    "    result_df = pd.DataFrame(result_list, columns=[\"query\", \"rank\", \"rank_result\"])\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    return EvaluationResults(\n",
    "        result_df,\n",
    "        mrr(result_df[\"rank\"]),\n",
    "        recall_at_k(result_df[\"rank\"], 1),\n",
    "        recall_at_k(result_df[\"rank\"], 5),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note collapse=\"true\"}\n",
    "## 実験用並列コード\n",
    "\n",
    "```python\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from itertools import cycle\n",
    "\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "@retry(wait=wait_exponential(multiplier=5, min=1, max=60), stop=stop_after_attempt(5))\n",
    "def retry_wrapper(func, *args, **kwargs):\n",
    "    return func(*args, **kwargs)\n",
    "\n",
    "\n",
    "def parallelize_function(funcs, args_list, kwargs_list=None, max_workers=10):\n",
    "    if kwargs_list is None:\n",
    "        kwargs_list = [{}] * len(\n",
    "            args_list\n",
    "        )  # Empty dictionaries if no kwargs are provided\n",
    "\n",
    "    if not isinstance(funcs, list):\n",
    "        funcs = [funcs]  # Make it a list if a single function is provided\n",
    "\n",
    "    # Ensure args_list and kwargs_list have the same length\n",
    "    if len(args_list) != len(kwargs_list):\n",
    "        raise ValueError(\"args_list and kwargs_list must have the same length.\")\n",
    "\n",
    "    results = [None] * len(args_list)  # Pre-allocate results list with None values\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures_to_index = {}\n",
    "        func_iter = cycle(funcs)  # Use itertools.cycle to handle function iteration\n",
    "\n",
    "        # Submit tasks to the executor\n",
    "        for i, (args, kwargs) in enumerate(zip(args_list, kwargs_list)):\n",
    "            func = next(func_iter)\n",
    "            future = executor.submit(retry_wrapper, func, *args, **kwargs)\n",
    "            futures_to_index[future] = i  # Map future to its index in args_list\n",
    "\n",
    "        # Collect results as tasks complete\n",
    "        for future in tqdm(\n",
    "            as_completed(futures_to_index),\n",
    "            total=len(futures_to_index),\n",
    "            desc=\"Processing tasks\",\n",
    "        ):\n",
    "            index = futures_to_index[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results[index] = result  # Place result in the corresponding index\n",
    "            except Exception as exc:\n",
    "                print(f\"Task {index} generated an exception: {exc}\")\n",
    "                results[index] = exc  # Store the exception in the results list\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# funcs = [chain1.invoke, chain2.invoke]  # List of functions for load balancing\n",
    "# args_list = [(arg1,), (arg2,), ...]  # List of argument tuples\n",
    "# kwargs_list = [{\"kwarg1\": value1}, {\"kwarg2\": value2}, ...]  # List of keyword argument dictionaries\n",
    "# results = parallelize_function(funcs, args_list, kwargs_list)\n",
    "```\n",
    "::: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### メタデータ実験\n",
    "今回はサマリーを生成し、それをベクトルとして追加します。\n",
    "\n",
    "まず必要なのはデータ生成です。まず簡単のプロンプトを書いて、それぞれのデータを生成します。これも本記事の本題ではないため、コードを折り畳みします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"データ生成用コード\"\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import HumanMessage\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "_ = load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\", request_timeout=20)\n",
    "\n",
    "def generate_metadata(msg, text_list, save_path):\n",
    "    metadata = []\n",
    "    for txt in tqdm(text_list):\n",
    "        result = llm([HumanMessage(content=msg.format(doc=txt))]).content.replace(\"\\n\", \" \")\n",
    "        metadata.append(result)\n",
    "\n",
    "    with open(save_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(metadata))\n",
    "\n",
    "\n",
    "msg = \"\"\"\n",
    "次のドキュメントを50字以内にサマリーしてください。\n",
    "===ドキュメント===\n",
    "{doc}\n",
    "\"\"\"\n",
    "text_list = a_df.Text.to_list()\n",
    "generate_metadata(msg, text_list, \"./3.5_turbo_summaries.txt\")\n",
    "\n",
    "with open(\"3.5_turbo_summaries.txt\", \"r\") as f:\n",
    "    summaries = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出力したデータのサンプルをお見せします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "資料が見つからない場合の確認事項は以下の通りです。受講生は自身が登録されているコースを確認し、資料の利用可能期間を確認してください。教員は科目に対応するコースに資料を掲載し、同じ曜日・時限・教室で開講する別の科目がないか確認し、フォルダやファイルが非表示になっていないか、利用可能期間が正しく設定されているかを確認してください。\n"
     ]
    }
   ],
   "source": [
    "print(summaries[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に直接ドキュメントに追加した場合とMulti-Vector Retrieverを使う場合の検索精度をみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_vector import MultiVectorRetriever, ParentDocumentRetriever\n",
    "from langchain.schema.document import Document\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "docs = [\n",
    "    Document(page_content=s, metadata={\"doc_id\": a_df.AID[i]})\n",
    "    for i, s in enumerate(a_df.Text.tolist())\n",
    "]\n",
    "\n",
    "summarys = [\n",
    "    Document(page_content=summaries[i], metadata={\"doc_id\": a_df.AID[i]})\n",
    "    for i, s in enumerate(a_df.Text.tolist())\n",
    "]\n",
    "\n",
    "\n",
    "doc_summarys = [\n",
    "    Document(\n",
    "        page_content=f\"summary: {summaries[i]} \\n text: {a_df.Text[i]}\",\n",
    "        metadata={\"doc_id\": a_df.AID[i]},\n",
    "    )\n",
    "    for i, s in enumerate(a_df.Text.tolist())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_doc = FAISS.from_documents(docs, OpenAIEmbeddings())\n",
    "vectorstore_summary = FAISS.from_documents(summarys, OpenAIEmbeddings())\n",
    "vectorstore_doc_summary = FAISS.from_documents(doc_summarys, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ecb027b0de34c3e98429f74abf3037c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing tasks:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0f65b4f1144dc6ac1ffb04598f5ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing tasks:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c3529886d94094bb9c4dd8f7aef9b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing tasks:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595d95e373d24e30b92501f5a8ba2ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing tasks:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d09a60ca22b4d208a915d80a69ee063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing tasks:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75745d4330a1462ea06e63147a7d377c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing tasks:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_result = parallel_evaluate(\n",
    "    query_list, lambda q: vectorstore_doc.similarity_search(q, k=DOC_NUM)\n",
    ")\n",
    "summary_result = parallel_evaluate(\n",
    "    query_list, lambda q: vectorstore_summary.similarity_search(q, k=DOC_NUM)\n",
    ")\n",
    "doc_summary_result = parallel_evaluate(\n",
    "    query_list, lambda q: vectorstore_doc_summary.similarity_search(q, k=DOC_NUM)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>mrr</th>\n",
       "      <th>recall_at_1</th>\n",
       "      <th>recall_at_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>only_doc</td>\n",
       "      <td>0.6777</td>\n",
       "      <td>0.5457</td>\n",
       "      <td>0.8454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc_summary</td>\n",
       "      <td>0.6612</td>\n",
       "      <td>0.5199</td>\n",
       "      <td>0.8407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>summary</td>\n",
       "      <td>0.6475</td>\n",
       "      <td>0.5035</td>\n",
       "      <td>0.8244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_id     mrr  recall_at_1  recall_at_5\n",
       "0     only_doc  0.6777       0.5457       0.8454\n",
       "2  doc_summary  0.6612       0.5199       0.8407\n",
       "1      summary  0.6475       0.5035       0.8244"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(\n",
    "    [\n",
    "        [\"only_doc\", doc_result.mrr, doc_result.recall_at_1, doc_result.recall_at_5],\n",
    "        [\"summary\", summary_result.mrr, summary_result.recall_at_1, summary_result.recall_at_5],\n",
    "        [\"doc_summary\", doc_summary_result.mrr, doc_summary_result.recall_at_1, doc_summary_result.recall_at_5],\n",
    "        ],\n",
    "    columns = [\"model_id\",\"mrr\",\"recall_at_1\",\"recall_at_5\"]\n",
    "    ).sort_values(\"mrr\", ascending=False)\n",
    "result_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ご覧の通り、それぞれ直接ドキュメントに追加する場合は、性能が逆に悪化しました。  \n",
    "\n",
    "次に説明の中と同じようにドキュメントとサマリーに結合した場合どうなるかをみてみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028458bb8a944d499ceb10afa3542ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing tasks:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "multi_vector_vectorstore = FAISS.from_documents(docs + summarys, OpenAIEmbeddings())\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryStore()\n",
    "# The retriever (empty to start)\n",
    "multi_vector_retriever = MultiVectorRetriever(\n",
    "    vectorstore=multi_vector_vectorstore,\n",
    "    docstore=store,\n",
    "    id_key=\"doc_id\",\n",
    "    search_kwargs={\"k\": 1000},\n",
    ")\n",
    "multi_vector_retriever.docstore.mset(list(zip(a_df.AID.tolist(), docs)))\n",
    "multi_vectore_result = parallel_evaluate(\n",
    "    query_list, lambda q: multi_vector_retriever.get_relevant_documents(q)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>mrr</th>\n",
       "      <th>recall_at_1</th>\n",
       "      <th>recall_at_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multi_vector</td>\n",
       "      <td>0.6830</td>\n",
       "      <td>0.5457</td>\n",
       "      <td>0.8501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>only_doc</td>\n",
       "      <td>0.6777</td>\n",
       "      <td>0.5457</td>\n",
       "      <td>0.8454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc_summary</td>\n",
       "      <td>0.6612</td>\n",
       "      <td>0.5199</td>\n",
       "      <td>0.8407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>summary</td>\n",
       "      <td>0.6475</td>\n",
       "      <td>0.5035</td>\n",
       "      <td>0.8244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model_id     mrr  recall_at_1  recall_at_5\n",
       "3  multi_vector  0.6830       0.5457       0.8501\n",
       "0      only_doc  0.6777       0.5457       0.8454\n",
       "1   doc_summary  0.6612       0.5199       0.8407\n",
       "2       summary  0.6475       0.5035       0.8244"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the result to the dataframe as a row \n",
    "new_row = {\n",
    "        \"model_id\": \"multi_vector\",\n",
    "        \"mrr\": multi_vectore_result.mrr,\n",
    "        \"recall_at_1\": multi_vectore_result.recall_at_1,\n",
    "        \"recall_at_5\": multi_vectore_result.recall_at_5,\n",
    "    },\n",
    "result_df = pd.concat([result_df, pd.DataFrame(new_row)], ignore_index=True)\n",
    "result_df.round(4).sort_values(\"mrr\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ドキュメントを文単位に切り、文単位で検索を行う  \n",
    "次にドキュメントを文単位に切り、文単位で検索を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc9c8951a55415eb1aec4eb4402de5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing tasks:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = [\n",
    "    Document(page_content=sent, metadata={\"doc_id\": a_df.AID[i]})\n",
    "    for i, s in enumerate(a_df.Text.tolist())\n",
    "    for sent in s.split(\"\\n\")\n",
    "]\n",
    "print(len(sentences))\n",
    "multi_vector_vectorstore_sent = FAISS.from_documents(sentences, OpenAIEmbeddings())\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryStore()\n",
    "# The retriever (empty to start)\n",
    "multi_vector_retriever_sent = MultiVectorRetriever(\n",
    "    vectorstore=multi_vector_vectorstore_sent,\n",
    "    docstore=store,\n",
    "    id_key=\"doc_id\",\n",
    "    search_kwargs={\"k\": 1000},\n",
    ")\n",
    "multi_vector_retriever_sent.docstore.mset(list(zip(a_df.AID.tolist(), docs)))\n",
    "multi_vector_retriever_sent_result = parallel_evaluate(\n",
    "    query_list, lambda q: multi_vector_retriever_sent.get_relevant_documents(q)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515d132241014b1b983db7e9ff4915eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing tasks:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "multi_vector_retriever_sent_result = parallel_evaluate(\n",
    "    query_list, lambda q: multi_vector_retriever_sent.get_relevant_documents(q)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>mrr</th>\n",
       "      <th>recall_at_1</th>\n",
       "      <th>recall_at_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>multi_vector_all_docs</td>\n",
       "      <td>0.6831</td>\n",
       "      <td>0.5433</td>\n",
       "      <td>0.8595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multi_vector</td>\n",
       "      <td>0.6830</td>\n",
       "      <td>0.5457</td>\n",
       "      <td>0.8501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>only_doc</td>\n",
       "      <td>0.6777</td>\n",
       "      <td>0.5457</td>\n",
       "      <td>0.8454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc_summary</td>\n",
       "      <td>0.6612</td>\n",
       "      <td>0.5199</td>\n",
       "      <td>0.8407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>multi_vector_sent</td>\n",
       "      <td>0.6600</td>\n",
       "      <td>0.5199</td>\n",
       "      <td>0.8454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>summary</td>\n",
       "      <td>0.6475</td>\n",
       "      <td>0.5035</td>\n",
       "      <td>0.8244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model_id     mrr  recall_at_1  recall_at_5\n",
       "4  multi_vector_all_docs  0.6831       0.5433       0.8595\n",
       "3           multi_vector  0.6830       0.5457       0.8501\n",
       "0               only_doc  0.6777       0.5457       0.8454\n",
       "1            doc_summary  0.6612       0.5199       0.8407\n",
       "5      multi_vector_sent  0.6600       0.5199       0.8454\n",
       "2                summary  0.6475       0.5035       0.8244"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row = {\n",
    "        \"model_id\": \"multi_vector_sent\",\n",
    "        \"mrr\": multi_vector_retriever_sent_result.mrr,\n",
    "        \"recall_at_1\": multi_vector_retriever_sent_result.recall_at_1,\n",
    "        \"recall_at_5\": multi_vector_retriever_sent_result.recall_at_5,\n",
    "    },\n",
    "result_df = pd.concat([result_df, pd.DataFrame(new_row)], ignore_index=True)\n",
    "result_df.round(4).sort_values(\"mrr\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
