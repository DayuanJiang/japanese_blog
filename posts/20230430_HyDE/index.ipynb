{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"HyDE 論文解読 Draft\"\n",
        "date: \"2023-04-30\"\n",
        "categories: [NLP, Information_retrieval, paper]\n",
        "---"
      ],
      "id": "6de90c8e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "論文URL：<https://arxiv.org/abs/2204.07496>\n",
        "\n",
        "# 1 Introduction\n",
        "\n",
        "Dense retrievalについて様々な研究が行われているが、Zero-shot dense retrievalはまだ難しい。多くの研究はMS-MARCOのような大規模なデータセットを使って転移学習をしているが、MS-MARCOが商用不可の制限があるし、他のドメインに汎化が難しい課題がある。一方、新たなデータをラベリングするためには莫大なコストがかかる。\n",
        "\n",
        "![](images/paste-1.png)\n",
        "\n",
        "この論文では教師なしのZero-shot dense retrievalの仕組HyDEを提案した。 従来のDense retrieverはQueryとDocumentとの類似度でランクを決めている。HyDEはQueryを利用して、まずLLMでそのQueryを答える仮想なDocumentを生成する。生成したDocumentとDocumentの類似度でランキングしている。\n",
        "\n",
        "## 2 Related works\n",
        "\n",
        "## 3 Methology\n",
        "\n",
        "## 4 Experiments\n",
        "\n",
        "仮想なDocumentはInstructGPTで生成した。生成したDocumentをContrieverを用いてEmbeddingに変換した。\n",
        "\n",
        "テストのデータとしては、MS-MARCOをベースとしたTREC DL19 DL20があり、BEIRからもLow-resourceのデータセットをいくつ利用した。また、英語以外、韓国語、日本語等データセットも使った。\n",
        "\n",
        "![web search query sets](images/paste-2.png)\n",
        "\n",
        "![low-resource datasets](images/paste-4.png)\n",
        "\n",
        "![non-English retrieval](images/paste-5.png){width=\"400\"}\n",
        "\n",
        "結果を見ると、教師なしの領域でHyDEは全面的に以前のContrieverを超えた。また、教師あるのモデルから比較しても遜色しない精度を出した。\n",
        "\n",
        "## 5 Analysis\n",
        "\n",
        "![](images/paste-6.png){width=\"300\"}\n",
        "\n",
        "当たり前だが、仮想なドキュメントを生成するLLMによって最終の精度が違う。また、HyDEは教師なしの手法だが、教師ありのRetrieverの精度も向上できる。\n",
        "\n",
        "## 実装\n",
        "\n",
        "HyDEはすでに[LangChain](https://python.langchain.com/en/latest/modules/chains/index_examples/hyde.html)で実装されている。\n"
      ],
      "id": "b81f5e90"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.chains import HypotheticalDocumentEmbedder\n",
        "\n",
        "base_embeddings = OpenAIEmbeddings()\n",
        "llm = OpenAI()\n",
        "\n",
        "# Load with `web_search` prompt\n",
        "embeddings = HypotheticalDocumentEmbedder.from_llm(llm, base_embeddings, \"web_search\")\n",
        "\n",
        "# Now we can use it as any embedding class!\n",
        "result = embeddings.embed_query(\"Where is the Taj Mahal?\")"
      ],
      "id": "7d9da864",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}