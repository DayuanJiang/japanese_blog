<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2023-07-16">
<meta name="description" content="今回はRAGのRetrieverの性能を比較しました。 その結果としては、 - Dense Retrieverの中でデフォルトのGPTのEmbeddingモデル+Cosine類似度の組み合わせるが一番良かったです。 - Sparse Retrieverの中でBM25は計算スピードが早くてそこそこ良いパフォーマンスを出せています。 - Hybridのやり方で、Dense RetrieverとSparse Retrieverを組み合わせると一番良い結果を出せています。">

<title>RAG質問応答システムに使うRetrieverの精度比較 – blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-57476271c5f0467c372e20ff5d25630e.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-edc0777d93aca8f084c81dbc6fa27f8b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-56TE34D1Z4"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-56TE34D1Z4', { 'anonymize_ip': true});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="http://www.linkedin.com/in/jiang-dayuan"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#tldr" id="toc-tldr" class="nav-link active" data-scroll-target="#tldr">TL;DR</a></li>
  <li><a href="#ragretrieval-augmented-generationとは" id="toc-ragretrieval-augmented-generationとは" class="nav-link" data-scroll-target="#ragretrieval-augmented-generationとは">RAG(Retrieval Augmented Generation)とは？</a></li>
  <li><a href="#使用するデータセット" id="toc-使用するデータセット" class="nav-link" data-scroll-target="#使用するデータセット">使用するデータセット</a></li>
  <li><a href="#評価対象と評価方法評価指標" id="toc-評価対象と評価方法評価指標" class="nav-link" data-scroll-target="#評価対象と評価方法評価指標">評価対象と評価方法、評価指標</a></li>
  <li><a href="#類似度の計算方法" id="toc-類似度の計算方法" class="nav-link" data-scroll-target="#類似度の計算方法">類似度の計算方法</a></li>
  <li><a href="#sparse-retrieverのモデル" id="toc-sparse-retrieverのモデル" class="nav-link" data-scroll-target="#sparse-retrieverのモデル">Sparse Retrieverのモデル</a></li>
  <li><a href="#hybrid-retriever" id="toc-hybrid-retriever" class="nav-link" data-scroll-target="#hybrid-retriever">Hybrid Retriever</a></li>
  <li><a href="#まとめ" id="toc-まとめ" class="nav-link" data-scroll-target="#まとめ">まとめ</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">RAG質問応答システムに使うRetrieverの精度比較</h1>
  <div class="quarto-categories">
    <div class="quarto-category">NLP</div>
    <div class="quarto-category">LLM</div>
  </div>
  </div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">July 16, 2023</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="tldr" class="level2">
<h2 class="anchored" data-anchor-id="tldr">TL;DR</h2>
<p>今回はRAGのRetrieverの性能を比較しました。 その結果としては、</p>
<ul>
<li><p>Dense Retrieverの中でデフォルトのGPTのEmbeddingモデル+Cosine類似度の組み合わせるが一番良かったです。</p></li>
<li><p>Sparse Retrieverの中でBM25は計算スピードが早くてそこそこ良いパフォーマンスを出せています。</p></li>
<li><p>Hybridのやり方で、Dense RetrieverとSparse Retrieverを組み合わせると一番良い結果を出せています。</p></li>
</ul>
</section>
<section id="ragretrieval-augmented-generationとは" class="level2">
<h2 class="anchored" data-anchor-id="ragretrieval-augmented-generationとは">RAG(Retrieval Augmented Generation)とは？</h2>
<p>RAG（Retrieval-Augmented Generation）は、自然言語処理（NLP）タスクのための最新の機械学習モデルの一つです。RAGは、質問応答、文章生成、要約作成などのタスクに適用されます。このモデルは、あらかじめ学習された情報を取得（retrieval）し、その情報を利用して文を生成（generation）することが特徴です。</p>
<p>RAGは、主に以下の2つのコンポーネントから構成されています。</p>
<ul>
<li><p>検索器（Retriever）：質問や入力文に関連する情報をデータセットから見つけ出す役割を担います。検索された情報は、文書や段落といった形式で提供されます。</p></li>
<li><p>生成器（Generator）：検索器から提供された情報を基に、適切な応答や文章を生成します。生成器は、Transformerベースのモデル（例：GPT-3、BART）で構築されることが一般的です。最近はOpenAIのGPTのAPIのを利用することが多いです。</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="image.png" class="img-fluid figure-img"></p>
<figcaption>RAG</figcaption>
</figure>
</div>
<p>生成器の部分はLLMを使うため、RAGの性能は検索器の性能に依存します。今回は、検索器の性能を比較しました。そのまとめは以下の図になります。</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="image-1.png" class="img-fluid figure-img"></p>
<figcaption>Alt text</figcaption>
</figure>
</div>
</section>
<section id="使用するデータセット" class="level2">
<h2 class="anchored" data-anchor-id="使用するデータセット">使用するデータセット</h2>
<p>今回使用するデータは東京都立大学のeラーニングシステムのQ&amp;Aデータです。このデータは、東京都立大学で導入されたeラーニングシステムのユーザーから2015年4月から2018年7月までに報告された問題点としてのQ&amp;Aデータを収集したものです。427の質問と79の回答が含まれています。質問にどの回答に紐づくかのラベルがあります。</p>
<p>データの様子は下記の通りです。</p>
<div id="cell-3" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="co"># https://zenodo.org/record/2783642</span></span>
<span id="cb1-3"><a href="#cb1-3"></a>q_df <span class="op">=</span> pd.read_csv(<span class="st">"https://zenodo.org/record/2783642/files/Questions.csv"</span>)</span>
<span id="cb1-4"><a href="#cb1-4"></a>a_df <span class="op">=</span> pd.read_csv(<span class="st">"https://zenodo.org/record/2783642/files/Answers.csv"</span>)</span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="bu">print</span>(<span class="st">"q_df.shape:"</span>, q_df.shape)</span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="bu">print</span>(<span class="st">"a_df.shape:"</span>, a_df.shape)</span>
<span id="cb1-7"><a href="#cb1-7"></a>q_df.columns <span class="op">=</span> [c.strip() <span class="cf">for</span> c <span class="kw">in</span> q_df.columns]</span>
<span id="cb1-8"><a href="#cb1-8"></a>a_df.columns <span class="op">=</span> [c.strip() <span class="cf">for</span> c <span class="kw">in</span> a_df.columns]</span>
<span id="cb1-9"><a href="#cb1-9"></a>df <span class="op">=</span> q_df.merge(a_df, on<span class="op">=</span><span class="st">"AID"</span>)</span>
<span id="cb1-10"><a href="#cb1-10"></a>df.columns <span class="op">=</span> [<span class="st">"query"</span>,<span class="st">"AID"</span>,<span class="st">"document"</span>]</span>
<span id="cb1-11"><a href="#cb1-11"></a></span>
<span id="cb1-12"><a href="#cb1-12"></a>metadata <span class="op">=</span> a_df[[<span class="st">"AID"</span>]].to_dict(orient<span class="op">=</span><span class="st">"records"</span>)</span>
<span id="cb1-13"><a href="#cb1-13"></a>documents <span class="op">=</span> a_df[<span class="st">"Text"</span>].tolist()</span>
<span id="cb1-14"><a href="#cb1-14"></a>query_list <span class="op">=</span> <span class="bu">list</span>(<span class="bu">zip</span>(q_df[<span class="st">"Text"</span>], q_df[<span class="st">"AID"</span>]))</span>
<span id="cb1-15"><a href="#cb1-15"></a>display(q_df.head(<span class="dv">3</span>))</span>
<span id="cb1-16"><a href="#cb1-16"></a>display(a_df.head(<span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>q_df.shape: (427, 2)
a_df.shape: (79, 2)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Text</th>
<th data-quarto-table-cell-role="th">AID</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>履修している授業で先生が資料をアップロードしているはずだが、コース上に資料が見当たらない。</td>
<td>A001</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>資料をマイページに置いたが、学生からは見えなかった。</td>
<td>A001</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>前期の科目の「資料」を学生から見られないようにするにはどうしたら良いか？</td>
<td>A001</td>
</tr>
</tbody>
</table>

</div>
</div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">AID</th>
<th data-quarto-table-cell-role="th">Text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>A001</td>
<td>資料が見つからない場合は、以下の点を確認してください。&lt;br&gt;&lt;br&gt;&lt;br&gt;【受講生編】&lt;...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>A002</td>
<td>資料のアップロードやお知らせ作成時の電子メールでの通知の有無は、各授業の担当教員が設定できま...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>A003</td>
<td>kibacoにはファイルへパスワードを設定する機能はありません。資料は受講生全員に開示されま...</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="評価対象と評価方法評価指標" class="level2">
<h2 class="anchored" data-anchor-id="評価対象と評価方法評価指標">評価対象と評価方法、評価指標</h2>
<p>以前の<a href="http://www.jiang.jp/posts/20230601_embedding_benchmark/">ポスト</a>は主にDense RetrieverのEmbeddingモデルを比較しました。今回は以下の角度で比較します。</p>
<ul>
<li>類似度の計算方法
<ul>
<li>Cosine類似度</li>
<li>MMR（Maximal Marginal Relevance）類似度</li>
<li>SVM</li>
</ul></li>
<li>Sparse Retrieverのモデル
<ul>
<li>BM25</li>
<li>TF-IDF</li>
</ul></li>
</ul>
<p>評価方法は以下の3つのステップです。</p>
<ol type="1">
<li>79のドキュメントをEmbeddingに変換し、FAISSのVectorstoreとして保存する。</li>
<li>427の質問をEmbeddingに変換し、FAISSのVectorstoreを使用して、79のドキュメントを近い順に並べる。</li>
<li>並んだ順番でEmbeddingの性能を評価する</li>
</ol>
<p>評価指標は以下の3つです。</p>
<ol type="1">
<li>Mean Reciprocal Rank（MRR）: 正解ドキュメントの順位の平均の逆数で、ランク全体を評価する指標。</li>
<li>Recall@1: 正解ドキュメントが1番目に並んでいるかどうかを評価する指標。</li>
<li>Recall@5: 正解ドキュメントが上位5位以内に入っているかどうかを評価する指標。</li>
</ol>
</section>
<section id="類似度の計算方法" class="level2">
<h2 class="anchored" data-anchor-id="類似度の計算方法">類似度の計算方法</h2>
<p>Embeddingを得た後、類似度の計算によく使う方法はCosine類似度です。それを今回のベースラインとします。</p>
<p>MMR（Maximal Marginal Relevance）とは、は検索クエリとの関連性を維持しつつも、検索結果多様性を持たすように検索結果の順位を並べ替える手法。推薦システムで使うことが多いです。(https://yolo-kiyoshi.com/2020/05/08/post-1781/)</p>
<p>SVMはもともと分類の機械学習モデルですが、それを検索に使うことをOpenAIの創立者karpathyがTwitterで提案しました。 「感覚」としてはCosine Similarlyより良いだけでLangchainに取り込まされました。 (https://github.com/karpathy/randomfun/blob/master/knn_vs_svm.ipynb)</p>
<p>評価用コードがないので折り畳みしました。興味がある方は下の「Show the code」をクリックしてください。</p>
<div id="cell-6" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="im">from</span> dataclasses <span class="im">import</span> dataclass</span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="im">from</span> tqdm.auto <span class="im">import</span> tqdm</span>
<span id="cb3-3"><a href="#cb3-3"></a></span>
<span id="cb3-4"><a href="#cb3-4"></a>DOC_NUM <span class="op">=</span> <span class="bu">len</span>(a_df)</span>
<span id="cb3-5"><a href="#cb3-5"></a><span class="at">@dataclass</span></span>
<span id="cb3-6"><a href="#cb3-6"></a><span class="kw">class</span> EvaluationResults:</span>
<span id="cb3-7"><a href="#cb3-7"></a>    result_df: pd.DataFrame</span>
<span id="cb3-8"><a href="#cb3-8"></a>    mrr: <span class="bu">float</span></span>
<span id="cb3-9"><a href="#cb3-9"></a>    recall_at_1: <span class="bu">float</span></span>
<span id="cb3-10"><a href="#cb3-10"></a>    recall_at_5: <span class="bu">float</span></span>
<span id="cb3-11"><a href="#cb3-11"></a></span>
<span id="cb3-12"><a href="#cb3-12"></a><span class="kw">def</span> mrr(rank_array):</span>
<span id="cb3-13"><a href="#cb3-13"></a>    <span class="cf">return</span> (<span class="dv">1</span> <span class="op">/</span> rank_array).mean()</span>
<span id="cb3-14"><a href="#cb3-14"></a></span>
<span id="cb3-15"><a href="#cb3-15"></a><span class="kw">def</span> recall_at_k(rank_array, k):</span>
<span id="cb3-16"><a href="#cb3-16"></a>    <span class="cf">return</span> (rank_array <span class="op">&lt;=</span> k).mean()</span>
<span id="cb3-17"><a href="#cb3-17"></a></span>
<span id="cb3-18"><a href="#cb3-18"></a><span class="kw">def</span> evaluate(query_list, search_func):</span>
<span id="cb3-19"><a href="#cb3-19"></a>    result_list <span class="op">=</span> []</span>
<span id="cb3-20"><a href="#cb3-20"></a>    <span class="cf">for</span> query, aid <span class="kw">in</span> tqdm(query_list):</span>
<span id="cb3-21"><a href="#cb3-21"></a>        rank_result <span class="op">=</span> get_rank(query, search_func<span class="op">=</span>search_func)</span>
<span id="cb3-22"><a href="#cb3-22"></a>        <span class="cf">if</span> aid <span class="kw">not</span> <span class="kw">in</span> rank_result:</span>
<span id="cb3-23"><a href="#cb3-23"></a>            rank <span class="op">=</span> DOC_NUM <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb3-24"><a href="#cb3-24"></a>        <span class="cf">else</span>:</span>
<span id="cb3-25"><a href="#cb3-25"></a>            rank <span class="op">=</span> rank_result.index(aid) <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb3-26"><a href="#cb3-26"></a>        </span>
<span id="cb3-27"><a href="#cb3-27"></a>        result_list.append((query, rank, rank_result))</span>
<span id="cb3-28"><a href="#cb3-28"></a></span>
<span id="cb3-29"><a href="#cb3-29"></a>    result_df <span class="op">=</span> pd.DataFrame(result_list, columns<span class="op">=</span>[<span class="st">"query"</span>, <span class="st">"rank"</span>, <span class="st">"rank_result"</span>])</span>
<span id="cb3-30"><a href="#cb3-30"></a>    <span class="cf">return</span> EvaluationResults(result_df, mrr(result_df[<span class="st">"rank"</span>]), recall_at_k(result_df[<span class="st">"rank"</span>], <span class="dv">1</span>), recall_at_k(result_df[<span class="st">"rank"</span>], <span class="dv">5</span>))</span>
<span id="cb3-31"><a href="#cb3-31"></a></span>
<span id="cb3-32"><a href="#cb3-32"></a><span class="kw">def</span> get_rank(query, search_func):</span>
<span id="cb3-33"><a href="#cb3-33"></a>    results <span class="op">=</span> search_func(query)</span>
<span id="cb3-34"><a href="#cb3-34"></a>    aid_list <span class="op">=</span> []</span>
<span id="cb3-35"><a href="#cb3-35"></a>    <span class="cf">for</span> doc <span class="kw">in</span> results:</span>
<span id="cb3-36"><a href="#cb3-36"></a>        aid <span class="op">=</span> metadata[documents.index(doc.page_content)][<span class="st">"AID"</span>]</span>
<span id="cb3-37"><a href="#cb3-37"></a>        aid_list.append(aid)</span>
<span id="cb3-38"><a href="#cb3-38"></a>    <span class="cf">return</span> aid_list</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-7" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="im">from</span> langchain.vectorstores <span class="im">import</span> FAISS</span>
<span id="cb4-2"><a href="#cb4-2"></a><span class="im">from</span> langchain.embeddings.openai <span class="im">import</span> OpenAIEmbeddings</span>
<span id="cb4-3"><a href="#cb4-3"></a><span class="im">from</span> langchain.retrievers <span class="im">import</span> KNNRetriever</span>
<span id="cb4-4"><a href="#cb4-4"></a><span class="im">from</span> langchain.retrievers <span class="im">import</span> SVMRetriever</span>
<span id="cb4-5"><a href="#cb4-5"></a><span class="im">from</span> langchain.retrievers <span class="im">import</span> TFIDFRetriever</span>
<span id="cb4-6"><a href="#cb4-6"></a><span class="im">from</span> langchain.retrievers <span class="im">import</span> ElasticSearchBM25Retriever</span>
<span id="cb4-7"><a href="#cb4-7"></a></span>
<span id="cb4-8"><a href="#cb4-8"></a>embedding_openai <span class="op">=</span> OpenAIEmbeddings()</span>
<span id="cb4-9"><a href="#cb4-9"></a></span>
<span id="cb4-10"><a href="#cb4-10"></a>faiss_vectorstore <span class="op">=</span> FAISS.from_texts(documents, embedding_openai)</span>
<span id="cb4-11"><a href="#cb4-11"></a></span>
<span id="cb4-12"><a href="#cb4-12"></a>svm_retriever <span class="op">=</span> SVMRetriever.from_texts(documents, embedding_openai)</span>
<span id="cb4-13"><a href="#cb4-13"></a>svm_retriever.k <span class="op">=</span> DOC_NUM</span>
<span id="cb4-14"><a href="#cb4-14"></a></span>
<span id="cb4-15"><a href="#cb4-15"></a>faiss_similarity_result <span class="op">=</span> evaluate(query_list, <span class="kw">lambda</span> q: faiss_vectorstore.similarity_search(q, k<span class="op">=</span>DOC_NUM))</span>
<span id="cb4-16"><a href="#cb4-16"></a>faiss_mmr_result <span class="op">=</span> evaluate(query_list, <span class="kw">lambda</span> q: faiss_vectorstore.max_marginal_relevance_search(q, k<span class="op">=</span>DOC_NUM))</span>
<span id="cb4-17"><a href="#cb4-17"></a>svm_result <span class="op">=</span> evaluate(query_list, <span class="kw">lambda</span> q: svm_retriever.get_relevant_documents(q))</span>
<span id="cb4-18"><a href="#cb4-18"></a></span>
<span id="cb4-19"><a href="#cb4-19"></a>result_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb4-20"><a href="#cb4-20"></a>    [</span>
<span id="cb4-21"><a href="#cb4-21"></a>        [<span class="st">"faiss_similarity"</span>, faiss_similarity_result.mrr, faiss_similarity_result.recall_at_1, faiss_similarity_result.recall_at_5],</span>
<span id="cb4-22"><a href="#cb4-22"></a>        [<span class="st">"faiss_mmr"</span>, faiss_mmr_result.mrr, faiss_mmr_result.recall_at_1, faiss_mmr_result.recall_at_5],</span>
<span id="cb4-23"><a href="#cb4-23"></a>        [<span class="st">"svm"</span>, svm_result.mrr, svm_result.recall_at_1, svm_result.recall_at_5],</span>
<span id="cb4-24"><a href="#cb4-24"></a>        ], </span>
<span id="cb4-25"><a href="#cb4-25"></a>    columns <span class="op">=</span> [<span class="st">"model_id"</span>,<span class="st">"mrr"</span>,<span class="st">"recall_at_1"</span>,<span class="st">"recall_at_5"</span>]</span>
<span id="cb4-26"><a href="#cb4-26"></a>    ).sort_values(<span class="st">"mrr"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>結果はこちらです。ご覧の通り、MMRとSVM両方ともベースラインより弱いです。特にSVMの性能がひどいです。またくCosine類似度の方法に比べにならないです。</p>
<div id="cell-9" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a>result_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">model_id</th>
<th data-quarto-table-cell-role="th">mrr</th>
<th data-quarto-table-cell-role="th">recall_at_1</th>
<th data-quarto-table-cell-role="th">recall_at_5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>faiss_similarity</td>
<td>0.685327</td>
<td>0.550351</td>
<td>0.868852</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>faiss_mmr</td>
<td>0.622978</td>
<td>0.550351</td>
<td>0.679157</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>svm</td>
<td>0.520898</td>
<td>0.388759</td>
<td>0.683841</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="sparse-retrieverのモデル" class="level2">
<h2 class="anchored" data-anchor-id="sparse-retrieverのモデル">Sparse Retrieverのモデル</h2>
<p>次にSparse RetriewerのBM25とTF-IDFを見ます。</p>
<p>TF-IDFとBM25は、情報検索において、ドキュメントと検索クエリの関連性を評価するために使用される代表的な手法です。単語のカウントをベースとしているため、得たドキュメントのベクトルはsparseになります。そのため、この手法をSparse Retrieverと呼びます。</p>
<p>このポストはその効果の紹介を目的しているので、TF-IDFとBM25の詳細な説明は折り畳みしました。興味がある方は下の青いバーをクリックください。</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
TF-IDFとBM25とは
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>TF-IDF</strong>: TF-IDFは、単語の重要度を評価するために使用される統計的手法です。TF-IDFは、2つの主要な要素で構成されています。 - TF（Term Frequency）：文書内での単語の出現頻度。単語が文書内で頻繁に出現するほど、その単語は文書内で重要であると考えられます。</p>
<ul>
<li>IDF（Inverse Document Frequency）：文書全体のセット（コーパス）における単語の希少性を測定する指標。単語が多くの文書で出現するほど、その単語は一般的であると考えられ、IDFの値は低くなります。逆に、単語が少数の文書でのみ出現する場合、その単語は特定の文書に特有であり、IDFの値が高くなります。</li>
</ul>
<p>TF-IDFスコアは、これら2つの要素の積として計算され、このスコアが高い単語ほど、検索クエリと関連性が高いと考えられます。</p>
<p><strong>BM25</strong>: BM25（Best Matching 25）は、TF-IDFを拡張した検索アルゴリズムで、検索クエリとドキュメントの関連性をより正確に評価することができます。BM25は、以下の特徴を持っています。</p>
<ul>
<li><p>長さ正規化：長いドキュメントは、短いドキュメントよりも多くの単語を持つため、TF-IDFでは不利になる可能性があります。BM25では、ドキュメントの長さを正規化することで、この問題を解決しています。</p></li>
<li><p>単語の出現頻度の飽和：単語がある一定の出現回数を超えると、その単語の重要度が飽和し、それ以上の出現回数が重要度に大きな影響を与えなくなります。これにより、ある単語が特定のドキュメントで極端に多く出現する場合でも、適切な関連性評価が可能になります。</p></li>
</ul>
<p>BM25スコアは、TF-IDFスコアを改善したものであり、検索クエリとドキュメントの関連性をより正確に評価することができます。多くの情報検索システムや検索エンジンでは、BM25が関連性スコアとして使用されています。</p>
</div>
</div>
</div>
<p>実装について、LangchainにあるTF-IDFモジュールには前処理がないため、それを追加しました。また、TF-IDFのモジュールに模倣してBM25を実装しました。</p>
<p>一点注意すべきところとしては、Sparse Retriewerは前処理が非常に重要です。今回の前処理は簡単にMecabでテキストを単語単位に分割し、ストップワードを除去しました。</p>
<div id="cell-11" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a><span class="im">from</span> __future__ <span class="im">import</span> annotations</span>
<span id="cb6-2"><a href="#cb6-2"></a></span>
<span id="cb6-3"><a href="#cb6-3"></a><span class="im">from</span> typing <span class="im">import</span> Any, Dict, Iterable, List, Optional, Callable</span>
<span id="cb6-4"><a href="#cb6-4"></a></span>
<span id="cb6-5"><a href="#cb6-5"></a><span class="im">from</span> pydantic <span class="im">import</span> BaseModel</span>
<span id="cb6-6"><a href="#cb6-6"></a></span>
<span id="cb6-7"><a href="#cb6-7"></a><span class="im">from</span> langchain.schema <span class="im">import</span> BaseRetriever, Document</span>
<span id="cb6-8"><a href="#cb6-8"></a></span>
<span id="cb6-9"><a href="#cb6-9"></a></span>
<span id="cb6-10"><a href="#cb6-10"></a><span class="kw">class</span> TFIDFRetriever(BaseRetriever, BaseModel):</span>
<span id="cb6-11"><a href="#cb6-11"></a>    vectorizer: Any</span>
<span id="cb6-12"><a href="#cb6-12"></a>    docs: List[Document]</span>
<span id="cb6-13"><a href="#cb6-13"></a>    tfidf_array: Any</span>
<span id="cb6-14"><a href="#cb6-14"></a>    k: <span class="bu">int</span> <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb6-15"><a href="#cb6-15"></a>    preprocess_func: Callable[[<span class="bu">str</span>], <span class="bu">str</span>] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb6-16"><a href="#cb6-16"></a></span>
<span id="cb6-17"><a href="#cb6-17"></a>    <span class="kw">class</span> Config:</span>
<span id="cb6-18"><a href="#cb6-18"></a>        <span class="co">"""Configuration for this pydantic object."""</span></span>
<span id="cb6-19"><a href="#cb6-19"></a></span>
<span id="cb6-20"><a href="#cb6-20"></a>        arbitrary_types_allowed <span class="op">=</span> <span class="va">True</span></span>
<span id="cb6-21"><a href="#cb6-21"></a></span>
<span id="cb6-22"><a href="#cb6-22"></a>    <span class="at">@classmethod</span></span>
<span id="cb6-23"><a href="#cb6-23"></a>    <span class="kw">def</span> from_texts(</span>
<span id="cb6-24"><a href="#cb6-24"></a>        cls,</span>
<span id="cb6-25"><a href="#cb6-25"></a>        texts: Iterable[<span class="bu">str</span>],</span>
<span id="cb6-26"><a href="#cb6-26"></a>        metadatas: Optional[Iterable[<span class="bu">dict</span>]] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb6-27"><a href="#cb6-27"></a>        tfidf_params: Optional[Dict[<span class="bu">str</span>, Any]] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb6-28"><a href="#cb6-28"></a>        preprocess_func: Optional[Callable[[<span class="bu">str</span>], <span class="bu">str</span>]] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb6-29"><a href="#cb6-29"></a>        <span class="op">**</span>kwargs: Any,</span>
<span id="cb6-30"><a href="#cb6-30"></a>    ) <span class="op">-&gt;</span> TFIDFRetriever:</span>
<span id="cb6-31"><a href="#cb6-31"></a>        <span class="cf">try</span>:</span>
<span id="cb6-32"><a href="#cb6-32"></a>            <span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb6-33"><a href="#cb6-33"></a>        <span class="cf">except</span> <span class="pp">ImportError</span>:</span>
<span id="cb6-34"><a href="#cb6-34"></a>            <span class="cf">raise</span> <span class="pp">ImportError</span>(</span>
<span id="cb6-35"><a href="#cb6-35"></a>                <span class="st">"Could not import scikit-learn, please install with `pip install "</span></span>
<span id="cb6-36"><a href="#cb6-36"></a>                <span class="st">"scikit-learn`."</span></span>
<span id="cb6-37"><a href="#cb6-37"></a>            )</span>
<span id="cb6-38"><a href="#cb6-38"></a></span>
<span id="cb6-39"><a href="#cb6-39"></a>        tfidf_params <span class="op">=</span> tfidf_params <span class="kw">or</span> {}</span>
<span id="cb6-40"><a href="#cb6-40"></a>        vectorizer <span class="op">=</span> TfidfVectorizer(<span class="op">**</span>tfidf_params)</span>
<span id="cb6-41"><a href="#cb6-41"></a>        <span class="cf">if</span> preprocess_func:</span>
<span id="cb6-42"><a href="#cb6-42"></a>            processed_texts <span class="op">=</span> [preprocess_func(t) <span class="cf">for</span> t <span class="kw">in</span> texts]</span>
<span id="cb6-43"><a href="#cb6-43"></a>            tfidf_array <span class="op">=</span> vectorizer.fit_transform(processed_texts)</span>
<span id="cb6-44"><a href="#cb6-44"></a>        <span class="cf">else</span>:</span>
<span id="cb6-45"><a href="#cb6-45"></a>            tfidf_array <span class="op">=</span> vectorizer.fit_transform(texts)</span>
<span id="cb6-46"><a href="#cb6-46"></a>        metadatas <span class="op">=</span> metadatas <span class="kw">or</span> ({} <span class="cf">for</span> _ <span class="kw">in</span> texts)</span>
<span id="cb6-47"><a href="#cb6-47"></a>        docs <span class="op">=</span> [Document(page_content<span class="op">=</span>t, metadata<span class="op">=</span>m) <span class="cf">for</span> t, m <span class="kw">in</span> <span class="bu">zip</span>(texts, metadatas)]</span>
<span id="cb6-48"><a href="#cb6-48"></a>        <span class="cf">return</span> cls(vectorizer<span class="op">=</span>vectorizer, docs<span class="op">=</span>docs, tfidf_array<span class="op">=</span>tfidf_array,preprocess_func<span class="op">=</span>preprocess_func,  <span class="op">**</span>kwargs)</span>
<span id="cb6-49"><a href="#cb6-49"></a></span>
<span id="cb6-50"><a href="#cb6-50"></a>    <span class="at">@classmethod</span></span>
<span id="cb6-51"><a href="#cb6-51"></a>    <span class="kw">def</span> from_documents(</span>
<span id="cb6-52"><a href="#cb6-52"></a>        cls,</span>
<span id="cb6-53"><a href="#cb6-53"></a>        documents: Iterable[Document],</span>
<span id="cb6-54"><a href="#cb6-54"></a>        <span class="op">*</span>,</span>
<span id="cb6-55"><a href="#cb6-55"></a>        tfidf_params: Optional[Dict[<span class="bu">str</span>, Any]] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb6-56"><a href="#cb6-56"></a>        preprocess_func: Optional[Callable[[<span class="bu">str</span>], <span class="bu">str</span>]] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb6-57"><a href="#cb6-57"></a>        <span class="op">**</span>kwargs: Any,</span>
<span id="cb6-58"><a href="#cb6-58"></a>    ) <span class="op">-&gt;</span> TFIDFRetriever:</span>
<span id="cb6-59"><a href="#cb6-59"></a>        texts, metadatas <span class="op">=</span> <span class="bu">zip</span>(<span class="op">*</span>((d.page_content, d.metadata) <span class="cf">for</span> d <span class="kw">in</span> documents))</span>
<span id="cb6-60"><a href="#cb6-60"></a>        <span class="cf">return</span> cls.from_texts(</span>
<span id="cb6-61"><a href="#cb6-61"></a>            texts<span class="op">=</span>texts, tfidf_params<span class="op">=</span>tfidf_params, metadatas<span class="op">=</span>metadatas, preprocess_func<span class="op">=</span>preprocess_func, <span class="op">**</span>kwargs</span>
<span id="cb6-62"><a href="#cb6-62"></a>        )</span>
<span id="cb6-63"><a href="#cb6-63"></a></span>
<span id="cb6-64"><a href="#cb6-64"></a>    <span class="kw">def</span> get_relevant_documents(<span class="va">self</span>, query: <span class="bu">str</span>) <span class="op">-&gt;</span> List[Document]:</span>
<span id="cb6-65"><a href="#cb6-65"></a>        <span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> cosine_similarity</span>
<span id="cb6-66"><a href="#cb6-66"></a>        <span class="cf">if</span> <span class="va">self</span>.preprocess_func:</span>
<span id="cb6-67"><a href="#cb6-67"></a>            query <span class="op">=</span> <span class="va">self</span>.preprocess_func(query)</span>
<span id="cb6-68"><a href="#cb6-68"></a>        query_vec <span class="op">=</span> <span class="va">self</span>.vectorizer.transform(</span>
<span id="cb6-69"><a href="#cb6-69"></a>            [query]</span>
<span id="cb6-70"><a href="#cb6-70"></a>        )  <span class="co"># Ip -- (n_docs,x), Op -- (n_docs,n_Feats)</span></span>
<span id="cb6-71"><a href="#cb6-71"></a>        results <span class="op">=</span> cosine_similarity(<span class="va">self</span>.tfidf_array, query_vec).reshape(</span>
<span id="cb6-72"><a href="#cb6-72"></a>            (<span class="op">-</span><span class="dv">1</span>,)</span>
<span id="cb6-73"><a href="#cb6-73"></a>        )  <span class="co"># Op -- (n_docs,1) -- Cosine Sim with each doc</span></span>
<span id="cb6-74"><a href="#cb6-74"></a>        return_docs <span class="op">=</span> []</span>
<span id="cb6-75"><a href="#cb6-75"></a>        <span class="cf">for</span> i <span class="kw">in</span> results.argsort()[<span class="op">-</span><span class="va">self</span>.k :][::<span class="op">-</span><span class="dv">1</span>]:</span>
<span id="cb6-76"><a href="#cb6-76"></a>            return_docs.append(<span class="va">self</span>.docs[i])</span>
<span id="cb6-77"><a href="#cb6-77"></a>        <span class="cf">return</span> return_docs</span>
<span id="cb6-78"><a href="#cb6-78"></a></span>
<span id="cb6-79"><a href="#cb6-79"></a>    <span class="cf">async</span> <span class="kw">def</span> aget_relevant_documents(<span class="va">self</span>, query: <span class="bu">str</span>) <span class="op">-&gt;</span> List[Document]:</span>
<span id="cb6-80"><a href="#cb6-80"></a>        <span class="cf">raise</span> <span class="pp">NotImplementedError</span></span>
<span id="cb6-81"><a href="#cb6-81"></a>    </span>
<span id="cb6-82"><a href="#cb6-82"></a>    </span>
<span id="cb6-83"><a href="#cb6-83"></a></span>
<span id="cb6-84"><a href="#cb6-84"></a><span class="kw">class</span> BM25Retriever(BaseRetriever, BaseModel):</span>
<span id="cb6-85"><a href="#cb6-85"></a>    vectorizer: Any</span>
<span id="cb6-86"><a href="#cb6-86"></a>    docs: List[Document]</span>
<span id="cb6-87"><a href="#cb6-87"></a>    k: <span class="bu">int</span> <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb6-88"><a href="#cb6-88"></a>    preprocess_func: Callable[[<span class="bu">str</span>], <span class="bu">str</span>] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb6-89"><a href="#cb6-89"></a>    tokenizer: Callable[[<span class="bu">str</span>], List[<span class="bu">str</span>]] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb6-90"><a href="#cb6-90"></a></span>
<span id="cb6-91"><a href="#cb6-91"></a>    <span class="kw">class</span> Config:</span>
<span id="cb6-92"><a href="#cb6-92"></a>        <span class="co">"""Configuration for this pydantic object."""</span></span>
<span id="cb6-93"><a href="#cb6-93"></a></span>
<span id="cb6-94"><a href="#cb6-94"></a>        arbitrary_types_allowed <span class="op">=</span> <span class="va">True</span></span>
<span id="cb6-95"><a href="#cb6-95"></a></span>
<span id="cb6-96"><a href="#cb6-96"></a>    <span class="at">@classmethod</span></span>
<span id="cb6-97"><a href="#cb6-97"></a>    <span class="kw">def</span> from_texts(</span>
<span id="cb6-98"><a href="#cb6-98"></a>        cls,</span>
<span id="cb6-99"><a href="#cb6-99"></a>        texts: Iterable[<span class="bu">str</span>],</span>
<span id="cb6-100"><a href="#cb6-100"></a>        metadatas: Optional[Iterable[<span class="bu">dict</span>]] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb6-101"><a href="#cb6-101"></a>        bm25_params: Optional[Dict[<span class="bu">str</span>, Any]] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb6-102"><a href="#cb6-102"></a>        preprocess_func: Optional[Callable[[<span class="bu">str</span>], <span class="bu">str</span>]] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb6-103"><a href="#cb6-103"></a>        tokenizer : Optional[Callable[[<span class="bu">str</span>], List[<span class="bu">str</span>]]] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb6-104"><a href="#cb6-104"></a>        <span class="op">**</span>kwargs: Any,</span>
<span id="cb6-105"><a href="#cb6-105"></a>    ) <span class="op">-&gt;</span> BM25Retriever:</span>
<span id="cb6-106"><a href="#cb6-106"></a>        <span class="cf">try</span>:</span>
<span id="cb6-107"><a href="#cb6-107"></a>            <span class="im">from</span> rank_bm25 <span class="im">import</span> BM25Okapi</span>
<span id="cb6-108"><a href="#cb6-108"></a>        <span class="cf">except</span> <span class="pp">ImportError</span>:</span>
<span id="cb6-109"><a href="#cb6-109"></a>            <span class="cf">raise</span> <span class="pp">ImportError</span>(</span>
<span id="cb6-110"><a href="#cb6-110"></a>                <span class="st">"Could not import rank_bm25, please install with `pip install "</span></span>
<span id="cb6-111"><a href="#cb6-111"></a>                <span class="st">"rank_bm25`."</span></span>
<span id="cb6-112"><a href="#cb6-112"></a>            )</span>
<span id="cb6-113"><a href="#cb6-113"></a>            </span>
<span id="cb6-114"><a href="#cb6-114"></a>        <span class="cf">if</span> preprocess_func:</span>
<span id="cb6-115"><a href="#cb6-115"></a>            texts_processed <span class="op">=</span> [preprocess_func(t) <span class="cf">for</span> t <span class="kw">in</span> texts]</span>
<span id="cb6-116"><a href="#cb6-116"></a>        <span class="cf">else</span>:</span>
<span id="cb6-117"><a href="#cb6-117"></a>            texts_processed <span class="op">=</span> texts</span>
<span id="cb6-118"><a href="#cb6-118"></a>            </span>
<span id="cb6-119"><a href="#cb6-119"></a>        <span class="cf">if</span> tokenizer:</span>
<span id="cb6-120"><a href="#cb6-120"></a>            tokenized_texts <span class="op">=</span> [tokenizer(t) <span class="cf">for</span> t <span class="kw">in</span> texts_processed]</span>
<span id="cb6-121"><a href="#cb6-121"></a>        <span class="cf">else</span>:   </span>
<span id="cb6-122"><a href="#cb6-122"></a>            tokenized_texts <span class="op">=</span> [t.split() <span class="cf">for</span> t <span class="kw">in</span> texts_processed]</span>
<span id="cb6-123"><a href="#cb6-123"></a>        </span>
<span id="cb6-124"><a href="#cb6-124"></a>        bm25_params <span class="op">=</span> bm25_params <span class="kw">or</span> {}</span>
<span id="cb6-125"><a href="#cb6-125"></a>        vectorizer <span class="op">=</span> BM25Okapi(tokenized_texts, <span class="op">**</span>bm25_params)</span>
<span id="cb6-126"><a href="#cb6-126"></a>        metadatas <span class="op">=</span> metadatas <span class="kw">or</span> ({} <span class="cf">for</span> _ <span class="kw">in</span> texts)</span>
<span id="cb6-127"><a href="#cb6-127"></a>        docs <span class="op">=</span> [Document(page_content<span class="op">=</span>t, metadata<span class="op">=</span>m) <span class="cf">for</span> t, m <span class="kw">in</span> <span class="bu">zip</span>(texts, metadatas)]</span>
<span id="cb6-128"><a href="#cb6-128"></a>        <span class="cf">return</span> cls(vectorizer<span class="op">=</span>vectorizer, docs<span class="op">=</span>docs, preprocess_func<span class="op">=</span>preprocess_func,  <span class="op">**</span>kwargs)</span>
<span id="cb6-129"><a href="#cb6-129"></a></span>
<span id="cb6-130"><a href="#cb6-130"></a>    <span class="at">@classmethod</span></span>
<span id="cb6-131"><a href="#cb6-131"></a>    <span class="kw">def</span> from_documents(</span>
<span id="cb6-132"><a href="#cb6-132"></a>        cls,</span>
<span id="cb6-133"><a href="#cb6-133"></a>        documents: Iterable[Document],</span>
<span id="cb6-134"><a href="#cb6-134"></a>        <span class="op">*</span>,</span>
<span id="cb6-135"><a href="#cb6-135"></a>        bm25_params: Optional[Dict[<span class="bu">str</span>, Any]] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb6-136"><a href="#cb6-136"></a>        preprocess_func: Optional[Callable[[<span class="bu">str</span>], <span class="bu">str</span>]] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb6-137"><a href="#cb6-137"></a>        tokenizer : Optional[Callable[[<span class="bu">str</span>], List[<span class="bu">str</span>]]] <span class="op">=</span> <span class="va">None</span>,        </span>
<span id="cb6-138"><a href="#cb6-138"></a>        <span class="op">**</span>kwargs: Any,</span>
<span id="cb6-139"><a href="#cb6-139"></a>    ) <span class="op">-&gt;</span> BM25Retriever:</span>
<span id="cb6-140"><a href="#cb6-140"></a>        texts, metadatas <span class="op">=</span> <span class="bu">zip</span>(<span class="op">*</span>((d.page_content, d.metadata) <span class="cf">for</span> d <span class="kw">in</span> documents))</span>
<span id="cb6-141"><a href="#cb6-141"></a>        <span class="cf">return</span> cls.from_texts(</span>
<span id="cb6-142"><a href="#cb6-142"></a>            texts<span class="op">=</span>texts, tfidf_params<span class="op">=</span>bm25_params, metadatas<span class="op">=</span>metadatas,preprocess_func<span class="op">=</span>preprocess_func, tokenizer<span class="op">=</span>tokenizer, <span class="op">**</span>kwargs</span>
<span id="cb6-143"><a href="#cb6-143"></a>        )</span>
<span id="cb6-144"><a href="#cb6-144"></a></span>
<span id="cb6-145"><a href="#cb6-145"></a>    <span class="kw">def</span> get_relevant_documents(<span class="va">self</span>, query: <span class="bu">str</span>) <span class="op">-&gt;</span> List[Document]:</span>
<span id="cb6-146"><a href="#cb6-146"></a>        <span class="cf">if</span> <span class="va">self</span>.preprocess_func:</span>
<span id="cb6-147"><a href="#cb6-147"></a>            query <span class="op">=</span> <span class="va">self</span>.preprocess_func(query)</span>
<span id="cb6-148"><a href="#cb6-148"></a>        tokenized_query <span class="op">=</span> query.split()</span>
<span id="cb6-149"><a href="#cb6-149"></a>        return_docs <span class="op">=</span> <span class="va">self</span>.vectorizer.get_top_n(tokenized_query,<span class="va">self</span>.docs, n<span class="op">=</span>DOC_NUM)</span>
<span id="cb6-150"><a href="#cb6-150"></a>        <span class="cf">return</span> return_docs</span>
<span id="cb6-151"><a href="#cb6-151"></a></span>
<span id="cb6-152"><a href="#cb6-152"></a>    <span class="cf">async</span> <span class="kw">def</span> aget_relevant_documents(<span class="va">self</span>, query: <span class="bu">str</span>) <span class="op">-&gt;</span> List[Document]:</span>
<span id="cb6-153"><a href="#cb6-153"></a>        <span class="cf">raise</span> <span class="pp">NotImplementedError</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-12" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a><span class="im">import</span> requests</span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="co"># download japanese stopwords</span></span>
<span id="cb7-3"><a href="#cb7-3"></a>url <span class="op">=</span> <span class="st">"https://raw.githubusercontent.com/stopwords-iso/stopwords-ja/master/stopwords-ja.txt"</span></span>
<span id="cb7-4"><a href="#cb7-4"></a>stopwords <span class="op">=</span> requests.get(url).text.split(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb7-5"><a href="#cb7-5"></a></span>
<span id="cb7-6"><a href="#cb7-6"></a><span class="im">import</span> MeCab</span>
<span id="cb7-7"><a href="#cb7-7"></a><span class="im">import</span> ipadic</span>
<span id="cb7-8"><a href="#cb7-8"></a></span>
<span id="cb7-9"><a href="#cb7-9"></a></span>
<span id="cb7-10"><a href="#cb7-10"></a><span class="co"># parser = MeCab.Tagger("-Owakati")</span></span>
<span id="cb7-11"><a href="#cb7-11"></a><span class="kw">def</span> extract_nouns_verbs(text):</span>
<span id="cb7-12"><a href="#cb7-12"></a>    parser <span class="op">=</span> MeCab.Tagger(ipadic.MECAB_ARGS)</span>
<span id="cb7-13"><a href="#cb7-13"></a>    parsed_text <span class="op">=</span> parser.parse(text)</span>
<span id="cb7-14"><a href="#cb7-14"></a>    lines <span class="op">=</span> parsed_text.split(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb7-15"><a href="#cb7-15"></a>    nouns_verbs <span class="op">=</span> []</span>
<span id="cb7-16"><a href="#cb7-16"></a></span>
<span id="cb7-17"><a href="#cb7-17"></a>    <span class="cf">for</span> line <span class="kw">in</span> lines:</span>
<span id="cb7-18"><a href="#cb7-18"></a>        <span class="cf">if</span> <span class="st">'名詞'</span> <span class="kw">in</span> line <span class="kw">or</span> <span class="st">'動詞'</span> <span class="kw">in</span> line <span class="kw">or</span> <span class="st">"形状詞"</span> <span class="kw">in</span> line:</span>
<span id="cb7-19"><a href="#cb7-19"></a>            parts <span class="op">=</span> line.split(<span class="st">'</span><span class="ch">\t</span><span class="st">'</span>)</span>
<span id="cb7-20"><a href="#cb7-20"></a>            word <span class="op">=</span> parts[<span class="dv">0</span>]</span>
<span id="cb7-21"><a href="#cb7-21"></a>            <span class="cf">if</span> <span class="kw">not</span> word.isascii():</span>
<span id="cb7-22"><a href="#cb7-22"></a>                nouns_verbs.append(word)</span>
<span id="cb7-23"><a href="#cb7-23"></a>    <span class="cf">return</span> nouns_verbs</span>
<span id="cb7-24"><a href="#cb7-24"></a></span>
<span id="cb7-25"><a href="#cb7-25"></a><span class="kw">def</span> preprocess(text):</span>
<span id="cb7-26"><a href="#cb7-26"></a>    token_list <span class="op">=</span> [token <span class="cf">for</span> token <span class="kw">in</span> extract_nouns_verbs(text) <span class="cf">if</span> token <span class="kw">not</span> <span class="kw">in</span> stopwords]</span>
<span id="cb7-27"><a href="#cb7-27"></a>    <span class="cf">return</span> <span class="st">" "</span>.join(token_list)</span>
<span id="cb7-28"><a href="#cb7-28"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-13" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a>tfidf_search <span class="op">=</span> TFIDFRetriever.from_texts(a_df[<span class="st">"Text"</span>].tolist(), preprocess_func<span class="op">=</span>preprocess)</span>
<span id="cb8-2"><a href="#cb8-2"></a>tfidf_search.k <span class="op">=</span> DOC_NUM</span>
<span id="cb8-3"><a href="#cb8-3"></a></span>
<span id="cb8-4"><a href="#cb8-4"></a>bm25_search <span class="op">=</span> BM25Retriever.from_texts(a_df[<span class="st">"Text"</span>].tolist(), preprocess_func<span class="op">=</span>preprocess)</span>
<span id="cb8-5"><a href="#cb8-5"></a>bm25_search.k <span class="op">=</span> DOC_NUM</span>
<span id="cb8-6"><a href="#cb8-6"></a></span>
<span id="cb8-7"><a href="#cb8-7"></a>tfidf_result <span class="op">=</span> evaluate(query_list, <span class="kw">lambda</span> query: tfidf_search.get_relevant_documents(query))</span>
<span id="cb8-8"><a href="#cb8-8"></a>bm25_result <span class="op">=</span> evaluate(query_list, <span class="kw">lambda</span> query: bm25_search.get_relevant_documents(query))</span>
<span id="cb8-9"><a href="#cb8-9"></a></span>
<span id="cb8-10"><a href="#cb8-10"></a>result_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb8-11"><a href="#cb8-11"></a>    [</span>
<span id="cb8-12"><a href="#cb8-12"></a>    [<span class="st">"bm25"</span>, bm25_result.mrr, bm25_result.recall_at_1, bm25_result.recall_at_5],</span>
<span id="cb8-13"><a href="#cb8-13"></a>    [<span class="st">"tfidf"</span>, tfidf_result.mrr, tfidf_result.recall_at_1, tfidf_result.recall_at_5]],</span>
<span id="cb8-14"><a href="#cb8-14"></a>    columns <span class="op">=</span> [<span class="st">"model_id"</span>,<span class="st">"mrr"</span>,<span class="st">"recall_at_1"</span>,<span class="st">"recall_at_5"</span>]</span>
<span id="cb8-15"><a href="#cb8-15"></a>    ).sort_values(<span class="st">"mrr"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>結果を見ましょう。Sparse Retriewerのほうは意外に良い結果がを得ています。計算の速さやコスト等を考えると相当試すべき手法です。</p>
<div id="cell-15" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a>result_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">model_id</th>
<th data-quarto-table-cell-role="th">mrr</th>
<th data-quarto-table-cell-role="th">recall_at_1</th>
<th data-quarto-table-cell-role="th">recall_at_5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>bm25</td>
<td>0.608793</td>
<td>0.475410</td>
<td>0.798595</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>tfidf</td>
<td>0.592323</td>
<td>0.454333</td>
<td>0.763466</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="hybrid-retriever" class="level2">
<h2 class="anchored" data-anchor-id="hybrid-retriever">Hybrid Retriever</h2>
<p>これまでDense RetrieverとSparse Retrieverを比較しました。機械学習の中でEnsembleという概念がありまして、つまり複数のモデルを組み合わせて、より良い結果を得ることができます。それと似たような概念で、Dense RetrieverとSparse Retrieverを組み合わせて、Hybrid Retrieverを作るとより良い結果を得ることができます。</p>
<p>Hybridのほうほうとしては、Reciprocal Rank Fusion（RRF）という手法を使います。RRFは、複数の検索結果を組み合わせて、より良い検索結果を得るための手法です。RRFは、検索結果のランキングを組み合わせることで、検索結果のランキングを改善します。RRFは、以下の手順で実行されます。</p>
<p><span class="math display">\[\operatorname{RRF}(d) = \sum_{i=1}^{n} \frac{1}{k + r_i(d)}\]</span></p>
<p>ここで、</p>
<p><span class="math inline">\(d\)</span> は検索結果のドキュメントです。 <span class="math inline">\(n\)</span> は統合する検索結果の数です。 <span class="math inline">\(r_i(d)\)</span> は、<span class="math inline">\(i\)</span>番目の検索結果におけるドキュメント<span class="math inline">\(d\)</span>の順位です。 <span class="math inline">\(k\)</span> は、RRFのパラメータです。この値を大きくすることで、検索結果の順位に対するペナルティを調整できます。通常、<span class="math inline">\(k\)</span>は60などの定数値をとります。</p>
<p>実際の例で語りましょう。</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>BM25 Ranking</th>
<th>Dense Ranking</th>
<th>Results</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>A</td>
<td>B</td>
<td>A: 1/1 + 1/3 = 1.3</td>
</tr>
<tr class="even">
<td>B</td>
<td>C</td>
<td>B: 1/2 + 1/1 = 1.5</td>
</tr>
<tr class="odd">
<td>C</td>
<td>A</td>
<td>C: 1/3 + 1/2 = 0.83</td>
</tr>
</tbody>
</table>
<p>(https://weaviate.io/blog/hybrid-search-explained)</p>
<p>上のように、BM25とDense Retriever両方の結果が出た後、それぞれのドキュメントのランクの逆数を足して、その結果をもとに並べ替えます。例えば、AはBM25の結果で1位、Dense Retrieverの結果で3位なので、Kが0の場合はAの最終のスコアは1/1 + 1/3 = 1.3となります。</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
パラメーター<span class="math inline">\(k\)</span>の影響
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math inline">\(k\)</span>パラメータは、RRFの式において検索結果の順位に対するペナルティを調整する役割を持っています。<span class="math inline">\(k\)</span>が大きいほど、順位が低いドキュメントへのペナルティが緩やかになります。逆に、<span class="math inline">\(k\)</span>が小さいほど、順位が低いドキュメントへのペナルティが厳しくなります。</p>
<p>具体的には、<span class="math inline">\(k\)</span>が大きい場合、異なる検索結果間で順位が低いドキュメントでも、それらの組み合わせによってRRFスコアが上がる可能性があります。これにより、検索結果の多様性が増すことが期待されます。</p>
<p>一方で、<span class="math inline">\(k\)</span>が小さい場合、順位が高いドキュメントがより重視されるため、検索結果の集中度が高まることが期待されます。ただし、あまりにも<span class="math inline">\(k\)</span>が小さいと、異なる検索結果間でのバランスが悪くなり、検索結果の統合効果が十分に発揮されない可能性があります。</p>
<p>通常、<span class="math inline">\(k\)</span>は60などの定数値をとりますが、実際の検索タスクや評価指標によって最適な<span class="math inline">\(k\)</span>の値は異なる場合があります。実際の応用においては、パラメータチューニングや交差検証を用いて適切な<span class="math inline">\(k\)</span>の値を決定することが望ましいです。</p>
</div>
</div>
</div>
<p>その実装は以下の通りです。</p>
<div id="cell-17" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a><span class="kw">def</span> weighted_reciprocal_rank_fusion(rank_lists, weights, k<span class="op">=-</span><span class="dv">1</span>):</span>
<span id="cb10-2"><a href="#cb10-2"></a>    <span class="co">"""</span></span>
<span id="cb10-3"><a href="#cb10-3"></a><span class="co">    Perform weighted Reciprocal Rank Fusion on multiple rank lists.</span></span>
<span id="cb10-4"><a href="#cb10-4"></a></span>
<span id="cb10-5"><a href="#cb10-5"></a><span class="co">    Args:</span></span>
<span id="cb10-6"><a href="#cb10-6"></a><span class="co">        rank_lists (list of lists): A list of rank lists, where each rank list contains unique items.</span></span>
<span id="cb10-7"><a href="#cb10-7"></a><span class="co">        weights (list of float): A list of weights corresponding to the rank lists.</span></span>
<span id="cb10-8"><a href="#cb10-8"></a><span class="co">        k (float, optional): A constant added to the rank, controlling the balance between the importance</span></span>
<span id="cb10-9"><a href="#cb10-9"></a><span class="co">            of high-ranked items and the consideration given to lower-ranked items. Default is 0.</span></span>
<span id="cb10-10"><a href="#cb10-10"></a></span>
<span id="cb10-11"><a href="#cb10-11"></a><span class="co">    Returns:</span></span>
<span id="cb10-12"><a href="#cb10-12"></a><span class="co">        list: The final aggregated list of items sorted by their weighted RRF scores in descending order.</span></span>
<span id="cb10-13"><a href="#cb10-13"></a><span class="co">    """</span></span>
<span id="cb10-14"><a href="#cb10-14"></a>    <span class="cf">if</span> k <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb10-15"><a href="#cb10-15"></a>        k <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> <span class="bu">len</span>(rank_lists[<span class="dv">0</span>])</span>
<span id="cb10-16"><a href="#cb10-16"></a></span>
<span id="cb10-17"><a href="#cb10-17"></a>    <span class="cf">if</span> <span class="bu">len</span>(rank_lists) <span class="op">!=</span> <span class="bu">len</span>(weights):</span>
<span id="cb10-18"><a href="#cb10-18"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Number of rank lists must be equal to the number of weights."</span>)</span>
<span id="cb10-19"><a href="#cb10-19"></a>    </span>
<span id="cb10-20"><a href="#cb10-20"></a>    rrf_scores <span class="op">=</span> {}</span>
<span id="cb10-21"><a href="#cb10-21"></a>    </span>
<span id="cb10-22"><a href="#cb10-22"></a>    <span class="cf">for</span> rank_list, weight <span class="kw">in</span> <span class="bu">zip</span>(rank_lists, weights):</span>
<span id="cb10-23"><a href="#cb10-23"></a>        <span class="cf">for</span> rank, item <span class="kw">in</span> <span class="bu">enumerate</span>(rank_list, start<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb10-24"><a href="#cb10-24"></a>            rrf_score <span class="op">=</span> weight <span class="op">*</span> (<span class="dv">1</span> <span class="op">/</span> (rank <span class="op">+</span> k))</span>
<span id="cb10-25"><a href="#cb10-25"></a>            </span>
<span id="cb10-26"><a href="#cb10-26"></a>            <span class="cf">if</span> item <span class="kw">in</span> rrf_scores:</span>
<span id="cb10-27"><a href="#cb10-27"></a>                rrf_scores[item] <span class="op">+=</span> rrf_score</span>
<span id="cb10-28"><a href="#cb10-28"></a>            <span class="cf">else</span>:</span>
<span id="cb10-29"><a href="#cb10-29"></a>                rrf_scores[item] <span class="op">=</span> rrf_score</span>
<span id="cb10-30"><a href="#cb10-30"></a></span>
<span id="cb10-31"><a href="#cb10-31"></a>    <span class="co"># Sort items by their RRF scores in descending order</span></span>
<span id="cb10-32"><a href="#cb10-32"></a>    sorted_items <span class="op">=</span> <span class="bu">sorted</span>(rrf_scores.keys(), key<span class="op">=</span><span class="kw">lambda</span> x: rrf_scores[x], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-33"><a href="#cb10-33"></a></span>
<span id="cb10-34"><a href="#cb10-34"></a>    <span class="cf">return</span> sorted_items</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-18" class="cell" data-execution_count="25">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1"></a>bm25_rank_result <span class="op">=</span> bm25_result.result_df[<span class="st">"rank_result"</span>]</span>
<span id="cb11-2"><a href="#cb11-2"></a>tfidf_rank_result <span class="op">=</span> tfidf_result.result_df[<span class="st">"rank_result"</span>]</span>
<span id="cb11-3"><a href="#cb11-3"></a>faiss_rank_result <span class="op">=</span> faiss_similarity_result.result_df[<span class="st">"rank_result"</span>]</span>
<span id="cb11-4"><a href="#cb11-4"></a></span>
<span id="cb11-5"><a href="#cb11-5"></a>fused_rank_result <span class="op">=</span> [</span>
<span id="cb11-6"><a href="#cb11-6"></a>    weighted_reciprocal_rank_fusion(</span>
<span id="cb11-7"><a href="#cb11-7"></a>        [bm25_rank_result[i],  faiss_rank_result[i]],</span>
<span id="cb11-8"><a href="#cb11-8"></a>        [<span class="fl">0.2</span>, <span class="fl">0.8</span>]</span>
<span id="cb11-9"><a href="#cb11-9"></a>)</span>
<span id="cb11-10"><a href="#cb11-10"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(bm25_rank_result))</span>
<span id="cb11-11"><a href="#cb11-11"></a>]</span>
<span id="cb11-12"><a href="#cb11-12"></a></span>
<span id="cb11-13"><a href="#cb11-13"></a>fused_rank_s <span class="op">=</span> [fused_rank_result[i].index(query_list[i][<span class="dv">1</span>]) <span class="op">+</span> <span class="dv">1</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(query_list))]</span>
<span id="cb11-14"><a href="#cb11-14"></a>fused_df <span class="op">=</span> bm25_result.result_df.copy()</span>
<span id="cb11-15"><a href="#cb11-15"></a>fused_df[<span class="st">"rank"</span>] <span class="op">=</span> fused_rank_s</span>
<span id="cb11-16"><a href="#cb11-16"></a></span>
<span id="cb11-17"><a href="#cb11-17"></a>fused_result <span class="op">=</span> EvaluationResults(fused_df,  mrr<span class="op">=</span>mrr(fused_df[<span class="st">"rank"</span>]), recall_at_1<span class="op">=</span>recall_at_k(fused_df[<span class="st">"rank"</span>], <span class="dv">1</span>), recall_at_5<span class="op">=</span>recall_at_k(fused_df[<span class="st">"rank"</span>], <span class="dv">5</span>))</span>
<span id="cb11-18"><a href="#cb11-18"></a></span>
<span id="cb11-19"><a href="#cb11-19"></a>result_dict <span class="op">=</span> {</span>
<span id="cb11-20"><a href="#cb11-20"></a>    <span class="st">"faiss__cosine_similarity"</span>: faiss_similarity_result,</span>
<span id="cb11-21"><a href="#cb11-21"></a>    <span class="st">"faiss_mmr"</span>: faiss_mmr_result,</span>
<span id="cb11-22"><a href="#cb11-22"></a>    <span class="st">"svm"</span>: svm_result,</span>
<span id="cb11-23"><a href="#cb11-23"></a>    <span class="st">"tfidf"</span>: tfidf_result,</span>
<span id="cb11-24"><a href="#cb11-24"></a>    <span class="st">"bm25"</span>: bm25_result,</span>
<span id="cb11-25"><a href="#cb11-25"></a>    <span class="st">"hybrid"</span>: fused_result,</span>
<span id="cb11-26"><a href="#cb11-26"></a>}</span>
<span id="cb11-27"><a href="#cb11-27"></a>result_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb11-28"><a href="#cb11-28"></a>    [</span>
<span id="cb11-29"><a href="#cb11-29"></a>        [k, v.mrr, v.recall_at_1, v.recall_at_5]</span>
<span id="cb11-30"><a href="#cb11-30"></a>        <span class="cf">for</span> k, v <span class="kw">in</span> result_dict.items()</span>
<span id="cb11-31"><a href="#cb11-31"></a>    ],</span>
<span id="cb11-32"><a href="#cb11-32"></a>    columns<span class="op">=</span>[<span class="st">"model_id"</span>, <span class="st">"mrr"</span>, <span class="st">"recall_at_1"</span>, <span class="st">"recall_at_5"</span>],</span>
<span id="cb11-33"><a href="#cb11-33"></a>).sort_values(<span class="st">"mrr"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>これでテストすると、Hyperのやり方は一番精度が良いことがわかります。</p>
<div id="cell-20" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a>result_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">model_id</th>
<th data-quarto-table-cell-role="th">mrr</th>
<th data-quarto-table-cell-role="th">recall_at_1</th>
<th data-quarto-table-cell-role="th">recall_at_5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">5</td>
<td>hybrid</td>
<td>0.703478</td>
<td>0.573770</td>
<td>0.882904</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">0</td>
<td>faiss__cosine_similarity</td>
<td>0.685327</td>
<td>0.550351</td>
<td>0.868852</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1</td>
<td>faiss_mmr</td>
<td>0.622978</td>
<td>0.550351</td>
<td>0.679157</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">4</td>
<td>bm25</td>
<td>0.608793</td>
<td>0.475410</td>
<td>0.798595</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3</td>
<td>tfidf</td>
<td>0.592323</td>
<td>0.454333</td>
<td>0.763466</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2</td>
<td>svm</td>
<td>0.520898</td>
<td>0.388759</td>
<td>0.683841</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="まとめ" class="level2">
<h2 class="anchored" data-anchor-id="まとめ">まとめ</h2>
<p>今回はRAGのRetrieverの性能を比較しました。 その結果としては、</p>
<ul>
<li><p>Dense Retrieverの中でデフォルトのGPTのEmbeddingモデル+Cosine類似度の組み合わせるが一番良かったです。</p></li>
<li><p>Sparse Retrieverの中でBM25は計算スピードが早くてそこそこ良いパフォーマンスを出せています。</p></li>
<li><p>Hybridのやり方で、Dense RetrieverとSparse Retrieverを組み合わせると一番良い結果を出せています。</p></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/jiang\.jp");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="AlbertRapp/blogComments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->




</body></html>