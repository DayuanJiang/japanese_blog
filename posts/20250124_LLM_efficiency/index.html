<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.340">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-01-24">
<meta name="description" content="MacBookでもLLMが動く理由を、計算力とメモリスピードの観点から解説。A100との比較や、推論速度の概算方法、2Pの経験則の検証などを通して、LLMの動作原理に迫ります。">

<title>blog - なぜLLMはMacBookでも動くのか？計算力とメモリから見るその仕組み</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-56TE34D1Z4"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-56TE34D1Z4', { 'anonymize_ip': true});
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="http://www.linkedin.com/in/jiang-dayuan" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#macbookでも意外にllmを動かすことができる" id="toc-macbookでも意外にllmを動かすことができる" class="nav-link active" data-scroll-target="#macbookでも意外にllmを動かすことができる">Macbookでも意外にLLMを動かすことができる</a></li>
  <li><a href="#gpuの仕組みを理解する" id="toc-gpuの仕組みを理解する" class="nav-link" data-scroll-target="#gpuの仕組みを理解する">GPUの仕組みを理解する</a></li>
  <li><a href="#実際に推論スピードを概算してみる" id="toc-実際に推論スピードを概算してみる" class="nav-link" data-scroll-target="#実際に推論スピードを概算してみる">実際に推論スピードを概算してみる</a>
  <ul class="collapse">
  <li><a href="#概算方法" id="toc-概算方法" class="nav-link" data-scroll-target="#概算方法">概算方法</a></li>
  <li><a href="#a100とmac-mini-m4を比較する" id="toc-a100とmac-mini-m4を比較する" class="nav-link" data-scroll-target="#a100とmac-mini-m4を比較する">A100とMac mini M4を比較する</a></li>
  </ul></li>
  <li><a href="#pの由来" id="toc-pの由来" class="nav-link" data-scroll-target="#pの由来">2Pの由来</a></li>
  <li><a href="#まとめ" id="toc-まとめ" class="nav-link" data-scroll-target="#まとめ">まとめ</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">なぜLLMはMacBookでも動くのか？計算力とメモリから見るその仕組み</h1>
  <div class="quarto-categories">
    <div class="quarto-category">LLM</div>
    <div class="quarto-category">Web</div>
  </div>
  </div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 24, 2025</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="macbookでも意外にllmを動かすことができる" class="level2">
<h2 class="anchored" data-anchor-id="macbookでも意外にllmを動かすことができる">Macbookでも意外にLLMを動かすことができる</h2>
<p>最近、OpenAIのO1レベルのOSSモデル、DeepSeek-R1が出ました。そして、XではM4 64GBのMac miniを8台繋いでクラスターにして、671Bのモデルを動かしたスレッドがありました。</p>
<blockquote class="twitter-tweet blockquote" data-media-max-width="560">
<p lang="en" dir="ltr">
</p><p>Running DeepSeek-V3 on M4 Mac Mini AI Cluster<br><br>671B MoE model distributed across 8 M4 Pro 64GB Mac Minis.<br><br>Apple Silicon with unified memory is a great fit for MoE. <a href="https://t.co/FmeARutaxq">pic.twitter.com/FmeARutaxq</a></p>
<p></p>
<p>— EXO Labs (<span class="citation" data-cites="exolabs">@exolabs</span>) <a href="https://twitter.com/exolabs/status/1872444906851229814?ref_src=twsrc%5Etfw">December 27, 2024</a></p>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>スレッドを見た時、「嘘だろう、671BのモデルをMac miniで動かせるの？」というのが最初の感想でした。色々調べた後、LLMを動かす際には、制限として主に「計算スピード」と「メモリのスピード」の2つがあることがわかりました。バッチサイズが1で推論する場合は、だいたい計算スピードではなく、メモリのスピードで足が引っ張られています。</p>
<p>例えば、<code>int4</code> で量子化したモデルで推論する場合、A100とMac mini M4を比較してみると、</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">デバイス</th>
<th style="text-align: right;">メモリスピード</th>
<th style="text-align: right;">計算力</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">A100</td>
<td style="text-align: right;">1935 GB/s</td>
<td style="text-align: right;">1248 TOPS</td>
</tr>
<tr class="even">
<td style="text-align: center;">Mac mini M4</td>
<td style="text-align: right;">120 GB/s</td>
<td style="text-align: right;">38 TOPS</td>
</tr>
<tr class="odd">
<td style="text-align: center;">A100/ Macmini</td>
<td style="text-align: right;">16x</td>
<td style="text-align: right;">32x</td>
</tr>
</tbody>
</table>
<p>A100の計算力はMac miniの32倍ですが、メモリスピードは16倍しかありません。なので理論上は、Mac miniはA100の1/16のスピードで出力することができます。</p>
<p>これからは、この話をさらに展開して原理までわかるようにします。</p>
</section>
<section id="gpuの仕組みを理解する" class="level2">
<h2 class="anchored" data-anchor-id="gpuの仕組みを理解する">GPUの仕組みを理解する</h2>
<p>CPU の構造とよく似ていて、GPUにもキャッシュがあります。下図でメモリのアーキテクチャを示しています。</p>
<p><img src="images/paste-4.png" class="img-fluid" width="456"></p>
<ul>
<li><p><strong>GPU SRAM：</strong> GPUの計算ユニット内蔵のメモリ。最速だが、最も容量が小さい（19TB/s、20MB）。</p></li>
<li><p><strong>GPU HBM：</strong> GPUのメインメモリ。中間の速度と容量（1.5TB/s、40GB）。</p></li>
<li><p><strong>メインメモリ DRAM：</strong> 最も低速だが、最も容量が大きい（12.8GB/s、&gt;1TB）。</p></li>
</ul>
<p>計算する前に、まずモデルのパラメータをCPUのメモリからGPU HBMに送る必要があります。<code>model.to("cuda")</code>はこの処理を行っています。計算する際に、必要なデータをHBMからGPUチップに内蔵されているSRAMに転送し、そこで計算を行います。計算が終わっていても、次のデータがまだ来ていない場合は、計算を止めて、データの転送を待たなければいけません。バッチサイズが小さい場合は、計算量が少ないため、データの転送を待つことになり、これがいわゆる「メモリバンド」です。</p>
</section>
<section id="実際に推論スピードを概算してみる" class="level2">
<h2 class="anchored" data-anchor-id="実際に推論スピードを概算してみる">実際に推論スピードを概算してみる</h2>
<section id="概算方法" class="level3">
<h3 class="anchored" data-anchor-id="概算方法">概算方法</h3>
<p>まず、概算するための式を示します。</p>
<p><span class="math display">\[
\text{latency}_\text{memory} := \dfrac{P\cdot n_{\text{bytes}}}{n_{\text{memory bandwidth}}}
\]</span></p>
<p><span class="math display">\[
\text{latency}_\text{compute} := \dfrac{2 \cdot P \cdot B}{n_{\text{flops}}}
\]</span></p>
<p>この中で、</p>
<ul>
<li><p><span class="math inline">\(P\)</span>はモデルのパラメータ数。</p></li>
<li><p><span class="math inline">\(n_{\text{bytes}}\)</span>はデータタイプに必要なバイト数。例えば、デフォルトのfp32を使う場合は4バイト、fp16の場合は2バイト、int4の場合は0.5バイト。</p></li>
<li><p><span class="math inline">\(n_{\text{memory bandwidth}}\)</span>は名前の通り、メモリ帯域幅のこと。</p></li>
<li><p><span class="math inline">\(B\)</span>はバッチサイズ。</p></li>
<li><p><span class="math inline">\(n_{\text{flops}}\)</span>は計算スピード</p></li>
</ul>
<p>メモリのレイテンシーは比較的わかりやすいです。分子は1トークンを計算するために計算ユニットのメモリ(SRAM)に送るデータ量のことです。それをメモリ帯域幅で割ると、データ転送の時間を概算することができます。</p>
<p>計算のレイテンシーは少しややこしいです。概算する際には、経験則で1トークンにかかる計算量を<span class="math inline">\(2P\)</span>とします(この後で詳細に計算してみます)。それをバッチサイズ<span class="math inline">\(B\)</span>に掛けると、<span class="math inline">\(B\)</span>個のトークンを計算するために必要な計算量になります。それを計算スピードで割ると、計算の時間を概算することができます。</p>
</section>
<section id="a100とmac-mini-m4を比較する" class="level3">
<h3 class="anchored" data-anchor-id="a100とmac-mini-m4を比較する">A100とMac mini M4を比較する</h3>
<p>これで、計算スピードとメモリスピードの比較ができるようになりました。表にある内容を式に代入して、A100とMac mini M4を実際に比較してみます。 ここでの前提条件としては、7Bのモデルをint4で推論する場合です。</p>
<table class="table">
<colgroup>
<col style="width: 38%">
<col style="width: 35%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">デバイス</th>
<th style="text-align: right;">メモリ観点で<br>1秒処理できるトークン数</th>
<th style="text-align: right;">計算力観点で<br>1秒処理できるトークン数</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">A100</td>
<td style="text-align: right;">552</td>
<td style="text-align: right;">89,142</td>
</tr>
<tr class="even">
<td style="text-align: center;">Mac mini M4</td>
<td style="text-align: right;">34</td>
<td style="text-align: right;">2,714</td>
</tr>
<tr class="odd">
<td style="text-align: center;">A100/ Macmini</td>
<td style="text-align: right;">16x</td>
<td style="text-align: right;">32x</td>
</tr>
</tbody>
</table>
<p>まず、デバイスごとに見ると、A100とMac mini M4の両方ともメモリスピードで足が引っ張られています。例えば、A100の場合は、計算力で概算すると、1秒に89,142トークンを処理できるのに対して、メモリスピードで概算すると、552トークンしか処理できません。Mac Mini M4も同じ状況です。</p>
<p>また、Mac Mini M4でも、一秒に34トークンを処理することができます。もし、Mac Mini M4 Proにすると、帯域幅が倍の273になり、処理できるトークン数も倍になります。</p>
<p>実際のテスト結果として、Mac Mini M4の計算スピードは大体<a href="https://github.com/ggerganov/llama.cpp/discussions/4167">24 tokens/sec</a>です。これは、概算の34 tokens/secと近いです。</p>
<p>計算のコードは以下です。</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a>P <span class="op">=</span> <span class="fl">7e9</span>  <span class="co"># 7Bモデル</span></span>
<span id="cb1-2"><a href="#cb1-2"></a>n_bytes <span class="op">=</span> <span class="fl">0.5</span>  <span class="co"># int4</span></span>
<span id="cb1-3"><a href="#cb1-3"></a>n_memory_bandwidth_A100 <span class="op">=</span> <span class="fl">1935e9</span></span>
<span id="cb1-4"><a href="#cb1-4"></a>n_memory_bandwidth_Macmini <span class="op">=</span> <span class="fl">120e9</span></span>
<span id="cb1-5"><a href="#cb1-5"></a></span>
<span id="cb1-6"><a href="#cb1-6"></a>n_tops_A100 <span class="op">=</span> <span class="fl">1248e12</span></span>
<span id="cb1-7"><a href="#cb1-7"></a>n_tops_Macmini <span class="op">=</span> <span class="fl">38e12</span></span>
<span id="cb1-8"><a href="#cb1-8"></a></span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="kw">def</span> memory_latency(n_bytes, n_memory_bandwidth, P):</span>
<span id="cb1-10"><a href="#cb1-10"></a>    <span class="cf">return</span> P <span class="op">*</span> n_bytes <span class="op">/</span> n_memory_bandwidth</span>
<span id="cb1-11"><a href="#cb1-11"></a></span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="kw">def</span> compute_latency(n_tops, P, B<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb1-13"><a href="#cb1-13"></a>    <span class="cf">return</span> <span class="dv">2</span> <span class="op">*</span> P <span class="op">*</span> B <span class="op">/</span> n_tops</span>
<span id="cb1-14"><a href="#cb1-14"></a></span>
<span id="cb1-15"><a href="#cb1-15"></a>memory_latency_A100 <span class="op">=</span> memory_latency(n_bytes, n_memory_bandwidth_A100, P)</span>
<span id="cb1-16"><a href="#cb1-16"></a>memory_latency_Macmini <span class="op">=</span> memory_latency(n_bytes, n_memory_bandwidth_Macmini, P)</span>
<span id="cb1-17"><a href="#cb1-17"></a></span>
<span id="cb1-18"><a href="#cb1-18"></a>compute_latency_A100 <span class="op">=</span> compute_latency(n_tops_A100, P)</span>
<span id="cb1-19"><a href="#cb1-19"></a>compute_latency_Macmini <span class="op">=</span> compute_latency(n_tops_Macmini, P)</span>
<span id="cb1-20"><a href="#cb1-20"></a></span>
<span id="cb1-21"><a href="#cb1-21"></a><span class="bu">print</span>(<span class="st">'1/memory_bandwidth_A100: '</span>, <span class="bu">int</span>(<span class="dv">1</span> <span class="op">/</span> memory_latency_A100))</span>
<span id="cb1-22"><a href="#cb1-22"></a><span class="bu">print</span>(<span class="st">'1/memory_bandwidth_Macmini: '</span>, <span class="bu">int</span>(<span class="dv">1</span> <span class="op">/</span> memory_latency_Macmini))</span>
<span id="cb1-23"><a href="#cb1-23"></a><span class="bu">print</span>(<span class="st">'1/compute_A100: '</span>, <span class="bu">int</span>(<span class="dv">1</span> <span class="op">/</span> compute_latency_A100))</span>
<span id="cb1-24"><a href="#cb1-24"></a><span class="bu">print</span>(<span class="st">'1/compute_Macmini: '</span>, <span class="bu">int</span>(<span class="dv">1</span> <span class="op">/</span> compute_latency_Macmini))</span>
<span id="cb1-25"><a href="#cb1-25"></a><span class="bu">print</span>(<span class="st">'A100/Macmini memory: '</span>, <span class="bu">int</span>(memory_latency_Macmini <span class="op">/</span> memory_latency_A100))</span>
<span id="cb1-26"><a href="#cb1-26"></a><span class="bu">print</span>(<span class="st">'A100/Macmini compute: '</span>, <span class="bu">int</span>(compute_latency_Macmini <span class="op">/</span> compute_latency_A100))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="pの由来" class="level2">
<h2 class="anchored" data-anchor-id="pの由来">2Pの由来</h2>
<p>最後に、なぜ<span class="math inline">\(2P\)</span>という計算量を使ったのかを説明します。簡単に言うと、LLMが推論する時、メインとなる処理は行列間の<code>matmul</code>です。<code>matmul</code>を一回することで、掛け算と足し算の2つの計算が行われます。そのため、1トークンを計算するためには、<span class="math inline">\(2P\)</span>の計算が必要です。</p>
<p>この<span class="math inline">\(2P\)</span>の経験則が本当に合理かを実際に計算してみましょう。</p>
<p>まず、そもそもTransformerのDecoderのアーキテクチャを復習しましょう。</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/paste-5.png" class="img-fluid figure-img" width="171"></p>
<figcaption class="figure-caption">GPT Architecture</figcaption>
</figure>
</div>
<p>トークンを生成する際に、計算のほとんどが全部真ん中のN個の灰色のブロックの中にあります。その中で、特に行列間の掛け算が計算量を多く消費する部分です。さらに詳細にいうと、<span class="math inline">\(d_{\text{model}}\)</span>はモデルの隠れ層の次元数とすると、計算量が<span class="math inline">\(d_{\text{model}}^2\)</span>の部分に主導されます。アルゴリズムの性能を把握する際に使うBig-O記法で言うと、<span class="math inline">\(O(d_{\text{model}}^2)\)</span>です。</p>
<p>これからは、TransformerのDecoderの灰色のブロックの中の計算量をステップごとに概算してみます。<a href="https://github.com/karpathy/nanoGPT/blob/master/model.py">nanoGPTのソースコード</a>と一緒に見ればもっと理解しやすいです。</p>
<ol type="1">
<li><span class="math inline">\(qkv\)</span>の計算<br>
Self-Attentionを計算する際に、まずは、インプットしてきたトークンのベクトル<span class="math inline">\(t_e\)</span> と ウェイト <span class="math inline">\(W_q, W_k, W_v\)</span> それぞれ掛け算する必要があります。 <span class="math display">\[
\begin{aligned}
q &amp;= t_e \cdot W_q \\
k &amp;= t_e \cdot W_k \\
v &amp;= t_e \cdot W_v
\end{aligned}
\]</span> ここでは、<span class="math inline">\(t_e \in \mathbb{R}^{1 \times d_{\text{model}}}\)</span>、<span class="math inline">\(W_q, W_k, W_v \in \mathbb{R}^{d_{\text{model}} \times d_{\text{model}}}\)</span>です。<br>
これで、この計算に必要なFlopsは、<span class="math inline">\(2 \cdot 3 \cdot d_{\text{model}}^2\)</span>です。 <span class="math inline">\(2\)</span>は1回の掛け算に必要な計算量、<span class="math inline">\(3\)</span>は<span class="math inline">\(W_q, W_k, W_v\)</span>の3つの行列を掛ける必要があるためです。</li>
<li>Attentionの計算<br>
次に、できた<span class="math inline">\(q, k, v\)</span>を使って、Attentionを計算します。 <span class="math display">\[\text{softmax}((q \cdot k) \div \sqrt{d_{\text{head}}}) \cdot v = z\]</span> このなかで、<span class="math inline">\(q, k, v \in \mathbb{R}^{1 \times d_{\text{model}}}\)</span>。<span class="math inline">\(q, k, v\)</span>が全部ベクトルのため、計算量は<span class="math inline">\(d_{\text{model}} + d_{\text{model}}\)</span>で、無視できます。</li>
<li>Attentionの出力を計算<br>
次にAttentionの出力を計算します。 <span class="math display">\[out = z \cdot W_o\]</span> この中で、<span class="math inline">\(z \in \mathbb{R}^{1 \times d_{\text{model}}}\)</span>、<span class="math inline">\(W_o \in \mathbb{R}^{d_{\text{model}} \times d_{\text{model}}}\)</span>。計算量は<span class="math inline">\(2 \cdot d_{\text{model}}^2\)</span>です。</li>
<li>Feed-Forwardの計算<br>
最後に、Feed-Forwardを計算します。式は以下です。 <span class="math display">\[
\begin{aligned}
out_1 &amp;= out \cdot W_1 \\
out_1 &amp;= \text{ReLU}(out_1) \\
out_2 &amp;= out_1 \cdot W_2
\end{aligned}
\]</span> 1行目について、<span class="math inline">\(W_1 \in \mathbb{R}^{d_{\text{model}} \times 4d_{\text{model}}}\)</span>、<span class="math inline">\(out_1 \in \mathbb{R}^{1 \times 4d_{\text{model}}}\)</span> のため、計算量は<span class="math inline">\(2 \cdot 4 \cdot d_{\text{model}}^2\)</span>です。<br>
2行目はReLUの計算なので、無視できます。<br>
3行目について<span class="math inline">\(W_2 \in \mathbb{R}^{4d_{\text{model}} \times d_{\text{model}}}\)</span>、<span class="math inline">\(out_2 \in \mathbb{R}^{1 \times d_{\text{model}}}\)</span>で、計算量は一行目と同じ<span class="math inline">\(2 \cdot 4 \cdot d_{\text{model}}^2\)</span>です。</li>
</ol>
<p>以上の計算を合計すると、1トークンを計算するためにレイヤー一層の計算量がわかります。 <span class="math display">\[
\begin{align*}
&amp;2 \cdot 3 \cdot d_{\text{model}}^2 + 2 \cdot d_{\text{model}}^2 + 2 \cdot 4 \cdot d_{\text{model}}^2 + 2 \cdot 4 \cdot d_{\text{model}}^2 \\
&amp;= 6 \cdot d_{\text{model}}^2 + 2 \cdot d_{\text{model}}^2 + 8 \cdot d_{\text{model}}^2 + 8 \cdot d_{\text{model}}^2 \\
&amp;= (6 + 2 + 8 + 8) \cdot d_{\text{model}}^2 \\
&amp;= 24 \cdot d_{\text{model}}^2 \\
\end{align*}
\]</span> さらに、それを層数<span class="math inline">\(N\)</span>で掛けると、<span class="math inline">\(24 \cdot n_{layers} \cdot d_{\text{model}}^2\)</span>になります。これが、1トークンを計算するために必要な計算量です。</p>
<p>これを7Bのモデルで計算する場合、<span class="math inline">\(d_{\text{model}} = 4096\)</span>、<span class="math inline">\(n_{layers} = 32\)</span>です。計算すると、<span class="math inline">\(24 \cdot 32 \cdot 4096^2 =12.9 \times 10^{9}\)</span>になります。7Bの2倍は14Bなので、約92%合っています。</p>
</section>
<section id="まとめ" class="level2">
<h2 class="anchored" data-anchor-id="まとめ">まとめ</h2>
<p>本文では、なぜGPUが弱小なMacBookでもLLMがちゃんと動作するのかについて、計算力とメモリスピードの観点から解説しました。LLMの計算パワーとメモリの速度という、普段はあまり気にしない2つの視点で、LLMの世界を少しだけ覗いてみました。高性能スポーツカーを前にして、馬力だけじゃなくタイヤのグリップや路面との摩擦まで気にしてしまうような、ちょっとマニアックな話だったかもしれません。</p>
<p>しかし、今DeepSeek-R1のようなOSSかつ高性能なモデルが出ているので、これからローカルでLLMを動かすことがますます増えると思います。その際に、この文章が役に立つでしょう。</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="AlbertRapp/blogComments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



</body></html>