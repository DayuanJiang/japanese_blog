{
  "hash": "d46be19684125e21da48b466ef1aa8ed",
  "result": {
    "markdown": "---\ntitle: \"LangserveとVercel AI SDKを使ってGenAIデモアプリをクイックに作る\"\ndate: 2024-8-15\ndescription-meta: \"\"\ncategories: [LLM, Web]\n---\n\n## Vercel AI SDKとは？\n\nVercel AI SDKは、Vercel社が提供するAIアプリケーション開発のための強力なフレームワークです。これを使えば、AIアプリケーションの開発が驚くほど簡単になります。\n\nVercel AI SDKは、以下の3つの主要なコンポーネントで構成されています。\n\n| ライブラリ  | 機能                                                                                   |\n|-------------------------|----------------------------------------------|\n| AI SDK Core | 統一されたAPIで任意のLLMを呼び出す（例: generateText、generateObject）                 |\n| AI SDK UI   | API経由でストリーミングチャットや生成UIを構築する（例: useChat）                       |\n| AI SDK RSC  | React Server Components (RSC) からクライアントへ生成UIをストリームする（例: streamUI） |\n\n## 利用シーン\n\n私はコンサルティングファームでAIエンジニアとして働いており、クライアントの要望に応じて様々なAIアプリケーションを開発しています。特に、提案段階で短期間でデモアプリを作成することがよくあります。\n\n簡単なアプリであれば、Vercel AI SDKのCore機能を使って、Next.js内で直接モデルを初期化し、すぐにコールすることができます。\n\nしかし、より複雑なアプリを作成する場合、通常はWebアプリ開発とAI開発が別々の担当者によって行われます。特にAI側では、PythonのLangChainを使うケースが多いです。そんな時に役立つのが、LangserveとVercel AI SDKを組み合わせたクイックな開発手法です。\n\n## 実例\n\n### LangChainで作ったAgent\n\n例えば、以下のような掛け算ツール`multiply`を持つAgentを構築しました。\n\n``` python\nimport os\n\nfrom langchain_openai import ChatOpenAI\n\nfrom langchain import hub\nfrom langchain.agents import AgentExecutor, create_tool_calling_agent\nfrom langchain.tools import tool\n\n\n@tool\ndef multiply(a: float, b: float) -> float:\n    \"\"\"Multiply two numbers.\n\n    Args:\n        a (float): The first number\n        b (float): The second number\n\n    Returns:\n        float: The result of multiplying\n    \"\"\"\n    return a * b\n\n\ndef create_agent():\n    llm = ChatOpenAI(\n        model='gpt-4o-mini', temperature=0, api_key=os.getenv('OPENAI_API_KEY')\n    )\n\n    prompt = hub.pull('hwchase17/openai-functions-agent')\n    prompt.messages\n    prompt.messages[0].prompt.template = \"\"\"\n    You are a helpful assistant. But you are not good at calculate math.\n    If you are asked to calculate math, you **must** use the tools that are available to you.\n    Do not try to calculate math on your own.\n    \"\"\"\n    tools = [multiply]\n    agent = create_tool_calling_agent(llm, tools, prompt)\n    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n    return agent_executor\n```\n\nこのAgentは、ユーザーの質問に対してツールを利用して回答します。\n\n``` python\nagent = create_agent()\nagent.invoke({\"input\":\"2*10\"})\n```\n\n```         \n> Entering new AgentExecutor chain...\n\nInvoking: `multiply` with `{'a': 2, 'b': 10}`\n\n20.0\n\nThe result of \\( 2 \\times 10 \\) is 20.\n\n> Finished chain.\n{'input': '2*10', 'output': 'The result of \\\\( 2 \\\\times 10 \\\\) is 20.'}\n```\n\n### LangServeでAgentをWebサーバー化する\n\nLangServeは、LangChainで作成したChainやAgentをREST APIとしてデプロイするのを支援するライブラリです。FastAPIとpydanticを使用してデータのチェックを行います。\n\n以下のコマンドでLangServeをインストールできます。\n\n``` bash\npip install \"langserve[all]\"\n```\n\n次に、`agent.py`と同じフォルダに以下の`app.py`を配置します。\n\n``` python\nfrom agent import create_agent\nfrom dotenv import load_dotenv\nfrom fastapi import FastAPI\nfrom langserve import add_routes\nfrom pydantic import BaseModel\n\nload_dotenv('../.env.local')\n\n\nclass Input(BaseModel):\n    input: str\n\n\nclass Output(BaseModel):\n    output: str\n\n\napp = FastAPI(\n    title='LangChain Server',\n    version='1.0',\n)\nagent = create_agent()\n\nadd_routes(\n    app,\n    agent.with_types(input_type=Input, output_type=Output),\n)\n\nif __name__ == '__main__':\n    import uvicorn\n\n    uvicorn.run(app, host='localhost', port=8000)\n```\n\nこれで、コマンドラインで`python app.py`を実行すれば、APIサーバーが[`http://localhost:8000`](http://localhost:8000)に立ち上がります。\n\nAPIをコールしてみましょう。\n\n``` bash\ncurl --location --request POST 'http://localhost:8000/invoke' \\\n    --header 'Content-Type: application/json' \\\n    --data-raw '{\n        \"input\": {\n            \"input\": \"2*2\"\n        }\n    }'\n```\n\n結果は以下の通りです。\n\n``` json\n{\n    'output': {'output': 'The result of \\\\( 2 \\\\times 2 \\\\) is 4.'},\n    'metadata': {\n        'run_id': '770fc929-6cbe-4779-b3a1-8aa4e5f5ca64',\n        'feedback_tokens': [],\n    },\n}\n```\n\n他の利用方法については、[`http://localhost:8000/docs/`](http://localhost:8000/docs#/)で確認できます。\n\n![](images/paste-1.png){fig-alt=\"doc\" fig-align=\"center\" width=\"252\"}\n\n### Vercel AI SDKでWebアプリを作成\n\n次に、Webアプリを作成します。\n\nまず、Next.jsのアプリを初期化します。選択肢はすべてデフォルトで進めます。\n\n``` bash\nnpx create-next-app@latest ai-agent\n```\n\n次に、必要なライブラリをインストールします。\n\n``` bash\nnpm install ai @ai-sdk/openai langchain\n```\n\n次に、Next.jsの`RSC`を使ってアプリを構築します。\n\n`/app/actions.tsx`を新しく作成し、以下の内容を追加します。`runAgent`関数にインプットが渡されると、以下の処理が行われます。\n\n1.  AI SDKでストリーミングデータ通信を行う`stream`を初期化。\n2.  Langchain.JSを使って、[`http://localhost:8000/`](http://localhost:8000/)のAPIとやり取りする`RemoteRunnable`を初期化。\n3.  `processStreamingEvents()`でインプットをAPIに入力し、結果を受け取り、`stream`の値を更新。\n4.  `stream`の値をクライアント側に返す。\n\n``` javascript\n\"use server\";\n\nimport { createStreamableValue } from \"ai/rsc\";\nimport { RemoteRunnable } from \"@langchain/core/runnables/remote\";\n\nexport async function runAgent(input: string) {\n    console.log(\"input\", input);\n    const stream = createStreamableValue();\n    const chain = new RemoteRunnable({\n        url: `http://localhost:8000/`,\n    });\n\n    async function processStreamingEvents() {\n        const streamingEvents = chain.streamEvents(\n            { input },\n            { version: \"v2\" }\n        );\n\n        for await (const item of streamingEvents) {\n            const formattedItem = JSON.parse(JSON.stringify(item, null, 2));\n            stream.update(formattedItem);\n        }\n\n        stream.done();\n    }\n\n    // Start processing the streaming events\n    processStreamingEvents();\n\n    return { streamData: stream.value };\n}\n```\n\n次に、画面に表示するために、`app/page.tsx`のコードを以下のように変更します。\n\nここでは、`./actions`から定義した`runAgent`をインポートし、ユーザーからのインプットを渡して、Agentの各操作の詳細をストリーミングイベントで取得し、それを逐次表示します。\n\n``` js\n\"use client\";\n\nimport React, { useState } from \"react\";\nimport { readStreamableValue } from \"ai/rsc\";\nimport { runAgent } from \"./actions\";\nimport { StreamEvent } from \"@langchain/core/tracers/log_stream\";\n\n\nexport default function Page() {\n    const [input, setInput] = useState(\"\");\n    const [data, setData] = useState<StreamEvent[]>([]);\n\n    async function handleSubmit(e: React.FormEvent) {\n        e.preventDefault();\n        if (!input) return;\n        const { streamData } = await runAgent(input);\n        for await (const item of readStreamableValue(streamData)) {\n            setData((prev) => [...prev, item]);\n        }\n    }\n\n    return (\n        <div>\n            <form onSubmit={handleSubmit}>\n                <input\n                    type=\"text\"\n                    value={input}\n                    onChange={(e) => setInput(e.target.value)}\n                    className=\"border border-gray-300 rounded-md p-2 mr-2\"\n                />\n                <button\n                    type=\"submit\"\n                    className=\"bg-blue-500 text-white px-4 py-2 rounded-md\"\n                >\n                    Run\n                </button>\n            </form>\n            <div className=\"h-200px overflow-y-scroll\">\n                {data.map((item, i) => (\n                    <>\n                        <div key={i} className=\"bg-slate-300\">\n                            {item.event}\n                        </div>\n                        <div key={i} className=\"\">\n                            {JSON.stringify(item.data)}\n                        </div>\n                    </>\n                ))}\n            </div>\n        </div>\n    );\n}\n```\n\n実際にインプットしてみると、以下のような結果が得られます。\n\n![](images/paste-2.png){fig-alt=\"result\" fig-align=\"center\" width=\"448\"}\n\nこれで、簡単にLangChainとVercel AI SDKを使ったデモアプリが完成しました。今はシンプルなフォーマットで表示していますが、すべてのデータを取得できているので、これを基にさらに多彩な表示や機能を追加することが可能です。\n\n例えば、ツールのインプット・アウトプットやAgentのメッセージをストリーミング形式で表示することもできます。\n\n<center>\n![](images/demo.webm){width=\"500px\"}\n</center>\n\n`app/page.tsx`のソースコードは長いので、隠します.\n\n```{js}\n#| fold: true\n\"use client\";\n\nimport React, { useState } from \"react\";\nimport { readStreamableValue } from \"ai/rsc\";\nimport { runAgent } from \"./actions\";\nimport { StreamEvent } from \"@langchain/core/tracers/log_stream\";\n\n\nexport default function Page() {\n    const [input, setInput] = useState(\"\");\n    const [data, setData] = useState<StreamEvent[]>([]);\n\n    async function handleSubmit(e: React.FormEvent) {\n        e.preventDefault();\n        if (!input) return;\n        const { streamData } = await runAgent(input);\n        for await (const item of readStreamableValue(streamData)) {\n            setData((prev) => [...prev, item]);\n        }\n    }\n    let chatResults: any = [];\n    for (let i = 0; i < data.length; i++) {\n        switch (data[i].event) {\n            case \"on_tool_start\":\n                chatResults.push({\n                    type: \"tool\",\n                    runID: data[i].run_id,\n                    input: data[i].data.input,\n                    output: null,\n                    name: data[i].name,\n                });\n                break;\n            case \"on_tool_end\":\n                const toolIndex = chatResults.findIndex(\n                    (item: any) => item.runID === data[i].run_id\n                );\n                chatResults[toolIndex].output = data[i].data.output;\n                break;\n            case \"on_chat_model_start\":\n                chatResults.push({\n                    type: \"message\",\n                    runID: data[i].run_id,\n                    output: \"\",\n                });\n                break;\n            case \"on_chat_model_stream\":\n                const messageIndex = chatResults.findIndex(\n                    (item: any) => item.runID === data[i].run_id\n                );\n                chatResults[messageIndex].output = chatResults[messageIndex].output + data[i].data.chunk.kwargs.content;\n                break;\n        }\n    }\n\n    return (\n        <div className=\"flex flex-col w-full gap-2\">\n            <form onSubmit={handleSubmit} className=\"flex flex-col w-full gap-2\">\n                <input\n                    type=\"text\"\n                    value={input}\n                    onChange={(e) => setInput(e.target.value)}\n                    className=\"border border-gray-300 rounded-md p-2 mr-2 w-full\"\n                />\n                <button\n                    type=\"submit\"\n                    className=\"bg-blue-500 text-white px-4 py-2 rounded-md\"\n                >\n                    Run\n                </button>\n            </form>\n            <div className=\"flex flex-col w-full gap-2\">\n                <div\n                    className=\"flex flex-col gap-2 px-2 h-[650px] overflow-y-auto\"\n                >\n                    {\n                        chatResults.map((item: any, i: number) => {\n                            switch (item.type) {\n                                case \"tool\":\n                                    return (\n                                        <div key={i} className=\"p-4 bg-slate-100 rounded-lg\">\n                                            <strong><code>{item.name}</code> Input</strong>\n                                            <pre className=\"break-all text-sm\">\n                                                {JSON.stringify(item.input, null, 2)}\n                                            </pre>\n                                            {item.output && (\n                                                <>\n                                                    <strong>Tool result</strong>\n                                                    <pre className=\"break-all text-sm\">\n                                                        {JSON.stringify(item.output, null, 2)}\n                                                    </pre>\n                                                </>\n                                            )}\n                                        </div>\n                                    );\n                                case \"message\":\n                                    if (item.output === \"\") return null;\n                                    return (\n                                        <div key={i} className=\"p-4 bg-slate-100 rounded-lg prose\">\n\n                                            {item.output}\n                                        </div>\n                                    );\n                                default:\n                                    return null;\n                            }\n\n                        })\n\n                    }\n                </div>\n            </div>\n        </div>\n    );\n}\n```\n\n---\n\nこのブログポストでは、LangserveとVercel AI SDKを使って、短期間で強力なGenAIデモアプリを作成する方法を紹介しました。これを活用すれば、クライアントへの提案やプロトタイプ作成が一層スムーズに進むことでしょう。ぜひ試してみてください！\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}