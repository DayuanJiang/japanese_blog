[
  {
    "objectID": "posts/jupyter-test/index.html",
    "href": "posts/jupyter-test/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "import numpy as np\na = np.arange(15).reshape(3, 5)\na\n\narray([[ 0,  1,  2,  3,  4],\n       [ 5,  6,  7,  8,  9],\n       [10, 11, 12, 13, 14]])"
  },
  {
    "objectID": "posts/jupyter-test/index.html#numpy",
    "href": "posts/jupyter-test/index.html#numpy",
    "title": "Post With Code",
    "section": "",
    "text": "import numpy as np\na = np.arange(15).reshape(3, 5)\na\n\narray([[ 0,  1,  2,  3,  4],\n       [ 5,  6,  7,  8,  9],\n       [10, 11, 12, 13, 14]])"
  },
  {
    "objectID": "posts/jupyter-test/index.html#matplotlib",
    "href": "posts/jupyter-test/index.html#matplotlib",
    "title": "Post With Code",
    "section": "Matplotlib",
    "text": "Matplotlib\n\nimport matplotlib.pyplot as plt\n\nfig = plt.figure()\nx = np.arange(10)\ny = 2.5 * np.sin(x / 20 * np.pi)\nyerr = np.linspace(0.05, 0.2, 10)\n\nplt.errorbar(x, y + 3, yerr=yerr, label='both limits (default)')\nplt.errorbar(x, y + 2, yerr=yerr, uplims=True, label='uplims=True')\nplt.errorbar(x, y + 1, yerr=yerr, uplims=True, lolims=True,\n             label='uplims=True, lolims=True')\n\nupperlimits = [True, False] * 5\nlowerlimits = [False, True] * 5\nplt.errorbar(x, y, yerr=yerr, uplims=upperlimits, lolims=lowerlimits,\n             label='subsets of uplims and lolims')\n\nplt.legend(loc='lower right')\nplt.show(fig)"
  },
  {
    "objectID": "posts/jupyter-test/index.html#plotly",
    "href": "posts/jupyter-test/index.html#plotly",
    "title": "Post With Code",
    "section": "Plotly",
    "text": "Plotly\n\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\nimport plotly.express as px\nimport plotly.io as pio\ngapminder = px.data.gapminder()\ngapminder2007 = gapminder.query(\"year == 2007\")\nfig = px.scatter(gapminder2007, \n                 x=\"gdpPercap\", y=\"lifeExp\", color=\"continent\", \n                 size=\"pop\", size_max=60,\n                 hover_name=\"country\")\nfig.show()"
  },
  {
    "objectID": "posts/20230428_inpars/index.html",
    "href": "posts/20230428_inpars/index.html",
    "title": "InPars 論文解読",
    "section": "",
    "text": "論文URL：https://arxiv.org/abs/2202.05144"
  },
  {
    "objectID": "posts/20230428_inpars/index.html#datasets",
    "href": "posts/20230428_inpars/index.html#datasets",
    "title": "InPars 論文解読",
    "section": "4.1 Datasets",
    "text": "4.1 Datasets\n今回使用したデータセットは以下：\n\nMS MARCO：Microsoftが出したBingの実際のユーザログをベースとした大型データセット。880万のドキュメントと50万のドキュメントとクエリーのペアがある。各クエリーが平均的に1ドキュメントに対応する。\nTREC-DL：MS MARCOと同じドキュメントを持っているが、クエリーは54件のみである。また、各クエリーについてアノテーションしたドキュメントが多い。\nRobust04：新聞領域のデータセット。52万のドキュメントがあり、249クエリーがある。各クエリーに対して、平均的に1250件のドキュメントをアノテーションした。\nNatural Questions：260万件のWikipediaテキストをベースとしたQuestion Answer データセット。QuestionはGoogleの検索エンジンのログから作ったもの。\nTREC-COVID：コロナの情報に関するデータセット"
  },
  {
    "objectID": "posts/20230428_inpars/index.html#training-data-generation",
    "href": "posts/20230428_inpars/index.html#training-data-generation",
    "title": "InPars 論文解読",
    "section": "4.2 Training Data Generation",
    "text": "4.2 Training Data Generation\n各学習データは（Query, Positive document, Negative document）のTripleによって構成させる。その生成のステップは以下：\n\n10万のドキュメントをサンプリングし、GPT3のCurieでQueryを生成させる。\n最終的にLog probabilityが上位の1万件のペアのみ学習データとして使う。\nBM25で検索した1000件の中でランダムに1件を抽出し、それをNegative Documentとする。（このやり方で多くのノイズを入れてしまうのでは？）\n\n以下は２点の補足：\n\n生成する際に温度とTopーPのパラメータ設定は結果に有意の影響しない。\n長さが300文字のドキュメントは捨てられる。\n\nQuery生成する際にPromptの書き方は2つを利用した（Figure２)：\n\n一般方法（Vanilla)：MS MARCOからランダムに3つのデータを抽出し、それを例として、FewーshotでQueryを生成させる。\nGBQ（Guided by Bad Questions）：一般方法と同じように、MS MARCOからランダムに3つのデータを抽出する。しかし、MS MARCOのQueryが漠然すぎるため、それをBad questionとして提示する。Documentを読んで、より関連するGood Questionを手動で作った。（Document, Good Question, Bad Question)で例を提示し、生成したGood QuestionをQueryとする。"
  },
  {
    "objectID": "posts/20230428_inpars/index.html#retrieval-methods",
    "href": "posts/20230428_inpars/index.html#retrieval-methods",
    "title": "InPars 論文解読",
    "section": "4.3 Retrieval Methods",
    "text": "4.3 Retrieval Methods\n２段階の検索を採用している。まずBM25で上位1000のドキュメントを取り出す。その次、MonoT5を使ってRerankingをする。\nMonoT5はTransformerのEncoderとDecoder両方とも使っているモデルで、Cross-Encoderモデルである。今回の実験では、サイズは220Mと3Bのモデルでテストした。\n各データセットにおいて作成された擬似データでMonoT5をFine-tuningした。"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "自然言語処理技術ブログ",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nInPars 論文解読\n\n\n\n\n\n\n\n\n\n\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nApr 27, 2023\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "このブログでは、自分が学んだ知識や経験を共有し、皆さんと一緒に成長していくことを目指しています。どうぞよろしくお願いいたします。"
  },
  {
    "objectID": "about.html#自己紹介",
    "href": "about.html#自己紹介",
    "title": "About",
    "section": "自己紹介",
    "text": "自己紹介\n私は2017年から社会人として働き始め、これまでに数々のデータサイエンスプロジェクトを経験してきました。自然言語処理に強い関心を持ち、KaggleやSignateなどでコンペに参加しています。詳細はLinkedInをご覧ください。"
  },
  {
    "objectID": "about.html#このブログの目的",
    "href": "about.html#このブログの目的",
    "title": "About",
    "section": "このブログの目的",
    "text": "このブログの目的\nブログを書く目的は主に以下の3つです。\n\n学んだ知識の理解を深めるため： 学んだことを他人に教えることは、自分自身の理解を深めることに繋がります。自分が理解できていない内容は他人に教えられないため、教えることを通じて自然と理解が深まります。\nプロフィールを充実させるため： 今後自己紹介が必要になった際に、このブログのリンクを共有することで相手に自分の興味や技術スタックを知ってもらえるようになります。\n他人の役に立つ情報を提供するため： これまでインターネット上の無料コンテンツの恩恵を受けてきました。私もコンテンツの消費者だけでなく、提供者としても活躍したいと考えています。"
  }
]